<!-- summary -->
總結：在建立初創企業的過程中，速度和具體性是成功的關鍵要素，尤其是在不斷變化的 AI 技術背景下。安德魯分享了他在 AI 基金中積累的經驗教訓，並強調了專注於具體想法以及建立有效的反饋循環的重要性，以提高初創企業的成功機會。

重點：
1. 執行速度是初創企業成功的重要指標，新興 AI 技術能夠促進更快的成長。
2. 最大的機會往往存在於應用層，具體的產品想法能為企業帶來快速構建的優勢。
3. 專家直覺在快速決策過程中至關重要，長期思考與用戶交流有助於形成有效的具體想法。
4. 建立反饋循環以獲取用戶意見，將改進產品設計並朝向市場適配發展。
5. 利用 AI 編程助手能顯著提升工程速度和降低成本，促使初創企業更加快速有效地推向市場。
<!-- endsummary -->

<small>原始影片：[https://www.youtube.com/watch?v=RNJCfif1dPY](https://www.youtube.com/watch?v=RNJCfif1dPY)</small>

### Andrew Ng <small>[00:02]</small>
真的很高興見到大家。今天我想做的事情是，既然這是創業學校，我想與你們分享一些我在 AI 基金中關於創建初創企業的經驗教訓。AI 基金是一個創業工作室，我們平均每月創建一個初創企業。由於我們共同創建初創企業，我們會直接參與編寫代碼、討論客戶、設計功能、確定定價。因此，我們不僅觀看他人創建初創企業，而是實際上與企業家們一起深入參與創建初創企業。我今天想分享的，是我在建立初創企業過程中所學到的一些教訓，特別是在這不斷變化的 AI 技術及其所賦予的能力方面，並且將焦點放在速度這一主題上。對於那些希望創建初創企業的人來說，我認為執行速度是一個強有力的成功預測指標。我對於能夠快速行動的企業家和高管們抱有極大的敬意，而新的 AI 技術正在使初創企業能夠更快成長。我希望分享一些最佳實踐，坦白說，這些實踐每兩到三個月仍在變化，讓你們能夠獲得那種速度，期望能提高你們的成功機會。在深入探討速度之前，許多人問我，嘿，安德魯，初創企業的機會在哪裡？我將這個視為 AI 堆棧，底層是半導體公司，然後是建立在其上的雲端超大規模服務商，許多 AI 基礎模型公司建立在其之上。儘管許多的公關、興奮和炒作都在這些技術層面上，但事實上，幾乎可以這樣定義，最大的機會必須在應用層，因為我們實際上需要應用來產生更多的收入，以便支付基礎雲和半導體的技術層。因此，不知何故，媒體和社交媒體往往不會談論應用層，但對於那些認為自己在建立初創企業的人，幾乎可以這樣定義，最大的機會必須在這裡，當然所有層級的機會都是存在的。

### Andrew Ng <small>[02:21]</small>
在過去的一年裡，許多事情發生了變化，如果你問我 AI 中最重要的技術趨勢是什麼，我會說是自主 AI 的崛起。大約一個半年前，我開始四處演講，試圖說服人們 AI 代理可能是一種趨勢，我沒有意識到大約去年夏天，一些市場營銷人員會抓住這個術語，並將其用作標籤，貼在所有可見的東西上，這使得它幾乎失去了一些意義，但我想從技術角度分享為什麼我認為自主 AI 是令人振奮和重要的，並且也為初創企業開啟了許多新的機會。因此，事實上，許多人使用 Language Model (LM) 的方式是提示它以生成輸出。我們讓 LM 輸出的方式就像是你走向一個人，或者在這種情況下，一個 AI，向它請求為你打出一篇論文，從第一個單詞到最後一個單詞，全部一次性完成，而從未使用過退格鍵。我們人類，如果被迫以這樣的直線順序打字，並不是在寫出最佳作品。同樣，AI 也不會。但儘管在這樣的直線方式寫作的困難，我們的 LMS 仍然出奇地好。通過自主工作流，我們可以對 AI 系統提出請求，請它首先寫一個論文大綱，然後如果需要進行一些網頁研究，抓取一些網頁以幫助提供背景，然後寫第一稿，然後閱讀第一稿、批評並修訂等。因此，我們最終形成了一種迭代工作流，其中你的模型進行了一些思考和研究，做了一些修改，然後再進行更多的思考，並在這一循環中多次回頭。這樣的過程雖然較慢，但輸出的結果卻更好。對於 AI 基金所處理的許多項目，從提取複雜的合規文件到醫療診斷，再到處理複雜法律文件的推理，我們發現這些自主工作流的差異非常大，影響它是否能夠運作。而許多需要做的工作，以及許多有價值的商業模式，仍然會針對現有工作流或新工作流進行發掘，並研究如何將其納入自主工作流中。

### Andrew Ng <small>[04:44]</small>
因此，對於 AI 堆棧的圖景，我想更新一下，過去一年新出現了一個自主編排層，幫助應用構建者編排或協調對底層技術層的大量調用。好消息是，這個編排層讓構建應用變得更加容易。但我認為，應用層必須是堆棧中最有價值的層這一基本結論仍然成立，並且存在著對應用層的偏愛或聚焦。現在讓我進入一些我所學到的，幫助初創企業加速的一些最佳實踐。事實上，在 AI 基金裡，我們只專注於具體的想法。因此，對我來說，一個具體的產品想法是指已經明確具體到足以讓一名工程師可以去構建它的想法。例如，如果你說讓我們使用 AI 來優化醫療資產，這實際上並不是一個具體的想法，它太模糊。如果你告訴我，這是一個使用 AI 來優化醫療資產的非常具體的軟件，不同的工程師可能會做出完全不同的事情，因為那不夠具體，你無法快速構建，而沒有速度。相比之下，如果你有一個具體的想法，比如讓我們編寫軟件，讓醫院的病人可以在線預約 MR 機器的時段以優化使用情況。我不知道這是否是一個好的或壞的具體想法。實際上業界已經這麼做了，但它是具體的，那意味著工程師可以快速構建。如果這是一個好想法，您會發現它不是一個好想法，但有具體的想法能夠為你帶來速度。或者有人說，讓我們使用 AI 來提高電子郵件的個人效率。這樣的想法有太多解釋，這樣的想法不夠具體。但如果有人說，你能否開發一個集成自動化的 Gmail 應用，用來過濾整個電子郵件，這就是具體的，我可以在今天下午就去構建它。因此，具體性為你帶來速度，而對許多企業家來說，令人誤解的是，模糊的想法往往會獲得很多讚譽。如果你告訴所有朋友，我們應該使用 AI 來優化醫療資產的使用，每個人都會說這是一個好主意，但這在某種意義上並不是一個能建造出來的好主意。事實上，當你模糊時，你幾乎總是是對的。但當你具體時，你可能是對的，也可能是錯的，兩者都很好。我們可以更快地發現這一點，而這對於初創企業來說是至關重要的。執行具體想法的過程中，我發現在 AI 基金，我要求我的團隊專注於具體的想法，因為具體的想法提供了明確的方向，團隊可以快速運行去實現它，並且無論是驗證、證明或推翻這個想法都可以而不需要太長時間。因此，我們可以快速做到這一點，而發現好的具體想法通常需要某人，可能是你或某個主題專家長期思考某個問題。

### Andrew Ng <small>[06:57]</small>
例如，在創立 Coursera 之前，我花了數年時間思考在線教育，與用戶交談，形成我對於什麼會成為優秀的教育技術平台的直覺。經過這段漫長的過程，我認為 YC 有時稱之為「在想法迷宮中徘徊」，但在長時間思考後，發現那些已經深思熟慮的人的直覺能夠快速作出決策，當你與專家交流，詢問應該構建這個功能還是那個功能時，直覺即是一個瞬時的決定，這可能是一個驚人有效的代理，如同在經過這些年的思考、與客戶交談之後，讓這位專家回答這樣的問題。你知道，直覺是一個瞬時的決定的所有經驗，令人驚訝的是它是一個意外優秀的代理，真的能用來作出決策。我知道我在從事 AI 的工作，你可能會認為我會說，我們需要數據。當然，我熱愛數據，但發現很多初創企業獲得數據其實是一個緩慢的決策機制。而主題專家擁有良好直覺，通常是一個做出快速決策的更好方式。還有另一件事對許多成功的初創企業來說，在任何時刻，你都是在追求一個非常明確的假設來建立和嘗試出售其價值。初創企業沒有資源去對沖並同時嘗試十個事情。因此，選一個即可，努力應對，如果數據告訴你要對此想法失去信心，那其實完全沒問題。只需迅速轉向追求一個完全不同的具體想法。因此，AI 基金經常感悟到的感覺是，我們果斷不移地追求一件事，直到世界告訴我們我們錯了，然後就立即轉變，追求另一個同樣的具體想法，同樣以堅定的決心和毅力進行。還有一個模式我見到的，如果每一條新數據都使你轉向，這可能意味著你的知識基礎太脆弱。如果每次你與客戶交談時，你都完全改變主意，這可能意味著你對該行業的了解還不夠深入，無法擁有一個高品質的具體想法，而找到某個專注於某個主題已久的人，可能會使你走上更多正確的方向，將速度提高。另一件我經常思考的事情是建立反饋循環，這在我們如何使用 AI 編程助手進行構建時正在迅速改變。因此，在創建許多應用時，最大風險之一是客戶接受度，很對初創企業面臨的挑戰不是因為我們無法建立我們想要構建的任何東西，而是因為我們構建的某些東西發現沒有人會在乎。因此，對於我創建初創企業的方法，特別是應用程式，較少的深度技術，較少的技術初創企業但絕對是應用初創企業，經常構建軟件，這是一個工程任務，然後獲得用戶的反饋，這是一個產品管理任務，然後基於用戶反饋調整我們對於要構建的東西的看法，再回到寫更多軟件，我們多次迭代這一循環，朝著產品市場適配發展，而發現借助 AI 編程助手來輔助編程，安德烈介紹的方式，快速工程變得可行，而這種方式以前是難以想象的。所以工程速度正在迅速上升，工程成本也在迅速下降。這改變了我們在這一循環中推動初創企業的機制。當我考慮我所做的軟件時，我發現大致可以劃分為兩個主要類別。有時我會構建快速的原型來測試一個想法。你可以說建立一個新的客戶服務聊天機器人。我們利用 AI 處理法律文件等等，建立一個快速的原型，看看我們認為它的效果如何。另一類型的軟件則是編寫和維護生產軟件，維護舊的軟件，但這些大規模的生產就緒代碼基礎取決於你信任的分析報告，從很難找到非常嚴謹的數據來看。在編寫生產質量代碼時，依賴 AI 系統的話，可能我們快 30%-50%。很難獲得嚴謹的數字；也許這個數字是合理的，但在構建快速原型時，我認為我們的速度遠超 50%，很可能是 10 倍更快，或許更多還有幾個原因，當你在構建獨立的原型時，與舊的軟件基礎設施的集成較少，需要的舊數據量也較少。而且在這種情況下，可靠性要求甚至可擴展性和安全性都要低得多。我知道我不應該告訴人們編寫不安全的代碼，對於這聽起來像是一個錯誤的事情，但我確實會要求我的團隊，“去吧，寫不安全的代碼。”因為如果這個軟件只會在你的筆記本上運行，你不打算惡意入侵自己的筆記本，那麼寫不安全的代碼是可以的。但當然，在似乎有效的情況下，請在發送給其他人之前將其進行安全處理。

### Andrew Ng <small>[09:10]</small>
在發送給其他人之前進行安全處理。此外，我發現越來越多的初創企業會系統性地通過建立 20 個原型來追求創新，看看什麼有效，因為我知道 AI 中有一些焦慮。很多概念證明沒有進入生產。但我認為，通過將概念證明的成本降低到足夠低，實際上，如果許多概念證明未能見光也沒有關係。我知道“快速行動並摧毀事物”這一口號受到負面評價，因為它的確摧毀了某些東西。一些團隊（對此的理解）得出了結論，認為不應快速行動，但我認為這是一個錯誤。我傾向於告訴我的團隊快速行動並負責任。我認為他們有很多方法可以在負責任的同時迅速行動。在 AI 助手的編碼環境中，我認為大約三、四年前的代碼自動完成功能（由 GitHub Copilot 推廣）變得流行，然後出現了很大一部分 AI 驅動的 IDE，這些工具在使用中獲得了很好的效果。然後從我不知道數個月前開始，出現了一代新的高度自主的編程助手，包括她正在使用的 o3。雲端代碼也很好。自從第 4 版發布以來，它已經變得非常出色，而如果幾個月後再問我，說不定我會使用不同的工具。然而，這些工具的發展速度是非常快的，但我認為雲端代碼是這一代高度自主編程助手的新一代，它正在持續提升開發者的生產力。有趣的是，即使只落後於一代或半代，與使用最新工具相比也會產生很大的差距，而我發現，我的團隊在軟件工程方面的做法與三、六個月前相比發生了很大的不同。一個令人驚訝的事情是，我們已經習慣將代碼視為一個非常有價值的文物，因為創建它是如此困難。但隨著軟件工程成本下降，代碼的價值正在下降。我所屬的團隊裡，例如，我們在上個月完全重建了一個代碼基礎三次，因為現在完全重建一個代碼基礎並不是那麼困難，選擇一個新的數據模式也不難，因為這樣做的成本已大幅下降。你們中的一些人可能聽說過 Jeff Bezos 對於雙向門與單向門的術語。雙向門是你可以做出決策的地方，如果你改變主意，可以相對便宜地回到原點。而單向門是你做出了一個決策，想要改變主意的話則代價高昂或非常困難。因此選擇你的技術堆棧的軟體架構過去是一個單向門，一旦你建立在某個技術堆疊上，設定了數據庫模式是非常困難的改變。這過去是單向門的一部分。我不想說這現在完全是雙向門，但我發現，我的團隊會在某個技術堆疊上構建一周後改變心意，然後將代碼基礎丟掉，從新技術堆疊開始重建。我不想過度炒作，我們並非總是這樣做，但重新做這個仍然是有成本的。但我發現，我的團隊正在經常重新思考什麼是一個單向門，現在什麼是一個雙向門，因為軟件工程的成本現在低得多。也許在超出軟件工程的範疇時，我覺得這實際上是很好的時機，讓每個人都能創建 AI。在過去的一年裡，一些人建議其他人不要學習編碼，理由是 AI 將會自動化。如果我們回顧這一點，會認為這是有史以來最糟糕的職業建議之一，因為隨著更好的工具使得軟件工程變得更容易，應該讓更多人來做，而不是更少。

### Andrew Ng <small>[11:26]</small>
因此，當幾十年前，世界從打孔卡移向鍵盤和終端時，使編碼變得更容易。當我們從組合語言轉變為高階語言如 COBOL 時，當時也有人爭辯，現在有了 COBOL，我們不需要程序員了，類似的，有人甚至為此寫了論文，但當然，這是錯誤的，編程語言使得編碼更容易，讓更多人學會編碼，文本 ID，即 AI 編程助手，隨著編碼變得更加容易，更多人應該學會編碼。我有一個有爭議的看法，實際上，我認為現在每個角色的人都應該學會編碼。事實上，在我的團隊中，我的 CFO、人才主管、招聘官、前台人員，所有人都會編碼，我實際上看到他們在所有工作職能中表現得更好，因為他們會編碼。我想，我可能稍微領先於潮流，大多數企業還沒有達到這一點，但在未來，我認為我們能讓每個人都能編碼，這會讓很多人變得更加高效。我還想與你們分享一個我學到的經驗教訓，為什麼我們應該讓人們學會編碼。當我在 Coursera 教授生成性 AI 課程時，我們需要生成背景藝術，例如使用 Midjourney，而我有一位團隊成員非常懂藝術史，所以他能夠準確掌握 Midjourney 的類型、色調和藝術靈感，對他生成的圖像有很好的控制。因此，我們最終使用了所有 Tommy 所生成的圖片。而相比之下，我不懂藝術史，因此當我提示圖像生成時，我可以說，請為我製作漂亮的機器人圖像。但我永遠無法像我的合作者那樣控制生成的結果。因此，我得不到他所能生成的優質圖像。我認為，對於計算機而言，未來最重要的技能之一是能夠精確告訴計算機你想要的東西，讓它們為你做到。而能夠深刻理解計算機的人將得以操控計算機以獲得你想要的結果。學習編碼，並不是說你需要自己編寫代碼，而是能夠讓 AI 為你編碼，似乎在未來將會是實現這一目的的最佳途徑。隨著軟件工程變得更快，另一方面的有趣動態是產品管理的工作，獲取用戶反饋，決定要構建哪些特徵，這正日益成為瓶頸，因此我在過去一年看到多個團隊有非常有趣的局面出現，我的許多團隊開始抱怨他們在產品工程和設計方面的瓶頸，因為工程師的速度變得非常快。我看到的一些有趣的趨勢是，三、四、五年前，矽谷曾經有這樣一些稍顯懷疑的經驗法則，但仍然是經驗法則，通常有 1 個產品經理對應 4 個工程師，或 1 PM 對 7 名工程師，這基本上是 PM 產品經理和工程師的比例，我們用一粒鹽來看待，但通常的情況是 1 PM 對 6-7 名工程師，但隨著工程師速度的加快，我不見得會看到產品管理工作，即設計產品的構建在與工程師加快的速度上變得更快。我看到這一比例出現變化，昨天下午，我的一個團隊第一次向我提出，當我們計畫一個項目的 Headcom 時，這個團隊提出的比例不是 1 PM 對 4 名工程師，而是 1 PM 對 0.5 名工程師。這個團隊實際上向我提出，我仍然不知道這是否是一個好的主意，這是我一生中第一次看到你知道管理者向我建議有兩倍的 PM，而不是工程師，這是非常有趣的動態，我仍然不知道我聽到的這個提案是否是一個好主意，但我覺得這是一個世界走向的標誌，會發現能編碼的 PM 或擁有某些產品直覺的工程師往往會表現得更好。

### Andrew Ng <small>[13:39]</small>
我發現對於初創企業領導者的重要之處在於，由於工程師的速度如此之快，如果你有良好的策略來快速獲取反饋以塑造你對於構建產品的看法，這也有助於你更快地推進。因此，我將通過一系列快速獲取產品反饋的策略來介紹，幫助你持續塑造你將決定構建的內容。我們將通過一個快速但可能不太準確的方式和一個慢而準確的方式的列表來查看。因此，獲取反饋的最快策略是自己查看產品，然後根據直覺判斷。如果你是某個主題的專家，其實這會非常有效。如果你知道你在做什麼，這措施會稍慢的方式是請三位朋友或隊友為你的產品獲取反饋。會再稍慢的方式是請三到十位陌生人求助給予反饋。當我建設產品時，獲得的重要技能之一是學會如何坐在咖啡館中，相對地，當我旅行時，我經常坐在飯店大廳。這里是在高人流量的地方學會看點，然後非常禮貌地要求陌生人提供任何產品的反饋，做到這一點過去是更容易的，當我不為人所知的時候。當人們認出你來時，這會變得稍微尷尬。我發現，我其實坐在高人流量的飯店大廳，並很有禮貌地請陌生人，“嘿，我們正在建立這個東西，你能否看一下。”在咖啡館裡，一些人在工作，還有許多人並不想工作，因此，我們給他們一個分心的理由，他們會非常樂意這樣做。事實上，我已經在飯店大廳或咖啡館裡與合作者做出了大量產品決策。接下來的做法是把原型發送給 100 名測試者。如果你有機會接觸一組目標用戶，將原型提供給更多用戶，這些方式會越慢越精確，還有一點是，我知道矽谷中，我們喜歡談論 AB 測試，當然，我進行很多 AB 測試，但與許多人認為相反的是，AB 測試在我所有的選單中現在成為了最慢的策略，因為發布它實在太慢了，這取決於你擁有多少用戶。然後，當你使用任何策略來獲取反饋時，一些團隊會查看數據並做出決策，但缺少的一部分是，當我進行 AB 測試的時候，我不僅僅是使用 AB 測試的結果來選擇產品 A 或產品 B。我的團隊經常會坐下來仔細地查看數據以改善我們的直覺，加快效率。我希望能夠使用早期的策略來做出高品質的決策，經常會坐下想，嘿，我認為這個產品名稱比另一個更好。但顯然，我的思維模型與用戶不符。事實上，聽著，這表明我們要坐下來使用所有的數據來更新我們的思維模型，以改善我們對於如何更快做出產品決策的直覺，這證明是非常重要的。好吧，我們談論了具體的想法、加速工程、加速產品反饋。接下來我想觸及一個問題，即理解 AI 實際上讓你變得更快。原因如下，作為一名 AI 專家，也許我會有偏見地支持 AI，但我想與你分享為什麼。事實上，當我們談論像移動互聯網這樣成熟的技術時，許多人使用手機已有很長時間。我們有時候了解一款移動應用程序可以做什麼。許多人包括非技術人士都對一款移動應用程序可以做的事具有良好的直覺。如果你看成熟的職業角色，例如銷售、市場營銷、人力資源和法律，它們都非常重要且非常困難。但你知道，有足夠的市場營銷人員在這個領域已經工作過很長時間，而在過去的一年裡，市場營銷策略並沒有太大改變。因此，有很多人在營銷上是非常優秀的，這非常重要但很困難，但這方面的知識相對分散。因為你知道，如何做好人力資源這方面的知識在過去六個月來並沒有足夠大的變化。然而，AI 是新興技術，因此，如何做好 AI 的知識並不廣泛，因此那些實際上能夠理解 AI 的團隊在對那些不能的人來說，確實存在優勢。

### Andrew Ng <small>[15:50]</small>
因此，當您遇到 AI 問題時，真正了解該問題是一個很有競爭優勢的能力。例如，客戶服務聊天機器人的準確度能夠達到什麼水平？你是否應該進行工作流的微調？如何實現低延遲的語音輸出？這些決策中有很多，如果你做出正確的技術決策，你可以在幾天內解決問題。如果做出錯誤的技術決策，你可能會在錯誤的道路上迷失三個月。當你有兩個可能的架構決策時，表面上看，這只給你一條信息，而聽起來是「如果你不知道正確答案，那麼你最多會慢兩倍」。但實踐中，如果你翻到錯誤的那個位元時，你並不僅僅是慢兩倍。你會耗費 10 倍的時間去追逐錯誤的方向。所以我認為，具備正確的技術判斷，真的能使初創企業更快地發展。我發現跟上 AI 的最新技術對於初創企業來說非常重要，這過去兩年來，我們見證了許多優秀的生成性 AI 工具或生成性 AI 模塊的出現，一些部分列表包括提示工作流、評估、Guardrails、RAG、語音輸出、異步編程、大量 ETL 嵌入、微調、圖数据库以及如何結合模型，這些都是能夠快速合作構建作產品的令我們驚訝的組件，而這些在一年前仍然無法實現。這為初創企業創造了許多新的建設機會。因此，當我了解這些模塊時，這是一個我腦海中的畫面。如果你擁有一個模塊，比如你有一個基本的白色積木，對，你可以構建一些酷的東西。也許你可以提示生成。因此，你擁有一個積木，你建立了一些了不起的東西。但如果你獲得第二個模塊，比如你也知道如何建造聊天機器人。所以你擁有一個白色的積木和一個黑色的積木，你可以構建更有趣的東西。如果你再獲得一個藍色的積木，你可以建造更有趣的東西。獲取幾個紅色的積木，也許再獲得一個小小的黃色積木，結合越多的積木越有趣，結合的過程非常快，越能在一起進行組合。因此，了解所有這些優秀的積木使得你能夠以更豐富的組合進行結合。我發現深度學習的課程，相信我自己參加了許多深度學習課程，因為我們與我認為幾乎所有全球最先進的 AI 公司合作，並且試著發放這些構建模塊。當我查看深度學習課程目錄時，這其實是我看到的任何時候。每當我上這些課程來學習這些構建模塊時，我發現我正在獲得新的東西，這些東西可以組合成以前無法想像的，從而形成更具創新性的軟件應用程序。因此，作為總結，這是我最後一頁。如果你們有任何問題，我希望能先回答。我發現有很多事物對於初創企業很重要，不僅僅是速度。但是，當我看到 AI 基金正在建立的初創企業時，我發現管理團隊的執行速度與成功機會高度相關。我們學到的一些加速速度的策略就是專注於具體的想法。這些想法必須是良好的具體的想法。我發現，作為一名高管，我會在速度和決策質量上受到評判，這兩者都很重要，但速度絕對重要。隨著 AI 編程助手的快速進入，使你變得更快，但這將瓶頸轉向了獲取用戶對產品決策的反饋，因此擁有一組獲取反饋的策略至關重要。如果你還沒有學會去咖啡館和陌生人交談，這並非易事，但只需保持禮貌，請在尊重的前提下行動，這對於每個企業家來說實際上都是非常有價值的技能，我認為保持跟上技術的進展也為你帶來速度，好的，謝謝你們。非常感謝大家。[掌聲] 請隨意提問。

### Andrew Ng <small>[18:09]</small>
隨著AI的進步，您是否認為對人類而言，開發工具更加重要，還是學習更好地使用工具更加重要？我們該如何定位自己，以便在智能化日益民主化的世界中保持必要性？我覺得 AGI 被過度炒作，許多事情長期以來都是人類可以做的，而 AI 卻無法做到。我認為未來，掌握如何使計算機準確執行你想做的事情的人將擁有更多的權力。因此，我認為跟上這些工具對於一些我們自己會建立工具的人來說會是重要的，但還有很多其他工具由其他人構建，而我們僅需要使用它們。能夠使用 AI 使計算機執行你想做的事情的人將會更強大，不用擔心人們的工作會消失，掌握 AI 的人會比不懂得人會更強大。

### Andrew Ng <small>[20:17]</small>
嗨，首先，謝謝你。我對你充滿敬意，我相信你是我們的真正榜樣。我的問題是關於計算的未來。隨著我們朝著更強大的 AI 前進，你覺得計算的發展方向會是什麼？我 mean 我們看到有人說要將 GPU 運送到太空，有人談論核能數據中心。你對這有何看法？對於我想要回應上一個問題的內容，我將這問題與上一個問題重疊。事實上，有一個框架可以用來判斷什麼是炒作，什麼不是炒作。我認為在過去的兩年中，有一些公司出於促銷、公關和募資的影響，對某些事情進行了炒作。由於 AI 是如此新穎，所以很多公司在沒有被人查核的情況下可以隨意聲稱幾乎所有事情，因為這項技術尚未被理解。因此，我的一個思維過濾器是，某些炒作敘述使這些企業看起來更具權力，這是被放大的。例如，這個觀念， AI 是如此強大，我們可能會意外致使人類滅絕，這是荒謬的。但這是一種炒作敘述，使得某些企業變得更強大，並且幫助它們達成募資目標。AI 是如此強大，很快就沒有人可以再擁有工作，這根本不正確。但這一點再次使這些企業看起來更強大，並且被過度炒作。我們強大到，只要訓練一個新模型，就可以輕鬆摧毀數千家初創企業，這根本不會發生。是的，Jasper 遇到了麻煩，少數幾個企業被摧毀，但並不是說隨便摧毀數千家公司是那麼容易。AI 需要大量的電力，只有核能才足夠可靠。你知道，風能和太陽能並不行，這事也是不對的。因此，我認為這些關於 GPU 在太空的問題……我不知道，看看吧。我想我們在地球上的 GPU 還有充分的發展空間。

### Andrew Ng <small>[22:28]</small>
是的，但我認為這些炒作敘述被誇大的，我認為這是一種扭曲，並不符合實際情況。幾乎沒有對於 AI 的過度炒作，沒有確切的證據，我們將如何與它一起建設未來。然而，有哪些最危險的偏見或過度炒作的敘事，您看到人們談論的或因此受到污染並最終採納的，我們應該避免或更多地意識到，可以讓我們在建設未來時獲得更為現實的視角？我認為危險的 AI 敘事已經被過度炒作。AI 是一種極好的工具，像其它任何一種強大工具一樣，像電一樣，有很多用來造福的方式，但也有一些有害的使用方式。我自己發現不太用 AI 安全這個詞，並不是因為我認為我們應該創建危險的事物，而是因為我認為安全並不是技術的功能，而是我們如何應用它的功能。就像電動馬達，你知道，電動馬達的製造商不能保證沒有人會用它來做一些不安全的下游任務，像使用電動馬達能夠構建一個彈道導彈或電動車，但電動馬達的製造商無法控制下游的使用。因此，安全不是電動馬達的功能，而是你如何應用它的功能，我認為 AI 也一樣，AI 既不安全，也不不安全，如何使用它才決定了它是否安全。因此，我常常不會將焦點放在 AI 的安全性上，而更偏向責任 AI，因為是我們如何負責，或不負責地應用它才會決定我們用 AI 技術所建造的最終作品，無論是有害還是有益。我覺得有時候一些真正非常特殊的情況會在新聞中被過度炒作，我想就前幾天《華爾街日報》有篇關於 AI 失控的文章，我覺得那篇文章將在實驗室中進行的極端案例實驗巨大化了，這讓人感到非常不對等，而這項實驗的實際情況是什麼。不幸的是，技術本身是如此複雜，許多人並不知道如何更好，這些炒作敘述不斷擴大，我感覺這真的是一種武器，也對開源軟件產生了影響，這真是可悲的。

### Andrew Ng <small>[24:45]</small>
謝謝你所做的工作。我認為你的影響是顯著的。我的問題是，作為有抱負的創始人，我們在一個能在一天內被擾亂的世界裡應該如何考慮業務？無論你有多麼好的模式、產品或功能，都能夠以 VIP 代碼進行復製，競爭對手能在基本的幾小時內完成。結果發現，當你開始一個企業時，有很多事情需要擔心。我擔心的首要問題是：你是否在構建用戶喜愛的產品？事實上，當你建立一家企業時，有很多事情需要考慮，包括市場渠道、競爭對手、技術模式等等，所有這些都很重要，但如果我只能聚焦於一件事，那就是：你是否構建用戶真正想要的產品？在你解決這一點之前，不太可能建立一個有價值的企業。解決這一問題後，其他問題會隨之而來，如：你有通道去獲取客戶嗎？長期定價會是怎樣的？你的防護垒又在何處？我發現，防護垒往往被過度炒作。事實上，我發現，越來越多的企業會以產品起步，然後最終演變成一個防護垒。但消費品的品牌更具有防禦性。倘若你擁有較大的動量，就會更難被追趕上。然而，針對企業產品而言，當你冒著較高的風險時，也許設置防護垒會更為考慮，當進入企業的渠道困難時。如果 AI 基金查看業務，我們實際上對這些因素進行了相當複雜的分析，然後撰寫了兩至六頁的敘述備忘錄來分析這些問題，在決定是否進行這一操作之前。我認為所有這些都是重要的，但我感受到了此刻的機會數量，即意味著在世界上許多事情是可能的，而尚未被人實現的東西，似乎遠比擁有技能的人數量要多。因此，在應用層，感覺有許多白色空間可以構建新東西，而沒有人似乎在從事這些工作。那我會說，專注於建立一款人們想要、甚至熱愛的產品，然後隨著時間找出其他的問題，儘管這一路上重要的還是要考慮周到。

### Andrew Ng <small>[27:18]</small>
嗨，教授，謝謝你出色的演講。我是一名來自史丹福的安德拉瑪瑞斯研究人員，我覺得你在講話中的隱喻非常有趣。你說，目前的 AI 工具就像積木，可以在累積的基礎上進行構建，但到目前為止，很難看到 AI 工具整合的累積性功能擴展，因為這些功能常常依賴於意圖分配的功能堆疊，並伴隨著令牌和時間的動態問題，這和靜態工程是不同的。所以，您認為未來可能的 agent 的累積效應的角度會是什麼？對於這點，我想快速說明一下。你提到的是 token 成本，我最常對開發者的建議是，首先的近似就是別擔心費用，只有小部分初創企業幸運地讓用戶使用那麼多，而令牌成本會成為一個問題，這確實可以成為問題。我一定也參加過一些團隊，因為用戶喜歡我們的產品，而我們開始查看帳單，這的確爬升到了一個非常成問題的地步，但事實上達到令牌用量成本成為問題的情況真的很難。對於我參與的團隊，當我們擁有的機會足夠帶來這樣的困擾時，我們通常會有解決方案來扭轉趨勢，例如優化提示或進行微調，就如 USD 優化，等等。然後我察覺到，許多自主的工作流事實上已經積成了不同的步驟。例如，如果你在構建客戶服務 chatbot，通常需要使用提示，優化一些結果，然後再進行評估，然後可能需要從 RAG 中獲得某些信息以回饋給用戶。因此，我確實看到這些事情在不斷增加，但對於許多開發者來說的一個提示是，我經常在設計軟件時，使從供應商之間的切換相對容易。因此，例如，我有很多產品是在 OM 基礎上建立的，但有時候我們會指向一個特定的項目問我，使用的 OM 是什麼時候，我實話實說，實際上，我不知道，因為我們已經建構了評估，當有一個新的模型釋出時，我們會快速進行評估，看看新模型是否優於舊模型。那麼，如果新的模型在評估中表現更好，我們將快速轉向新的模型，最終我們會每周都有不同的模型。有時候我們的引擎會改變，而我甚至都沒有告訴我。也因此，對於基礎模型的切換成本相對較低。我們經常建構了我們的軟件考量到這個，哦，AI 套件正在開源，這是我和我的朋友合作的努力，以便使切換更容易。而對於建構的平台的切換成本會難得多，但是我對保留在築積木選擇的彈性越來越重視，因此即使你能在不斷構建更多東西的情況下也能加快速度，所以希望能有幫助。

### Andrew Ng <small>[29:42]</small>
在 AI 的教育領域，主要有兩種範式。一個是 AI 可以使教師更加高效，例如自動批改和自動完成作業。但是另一種想法是每個學生都有個人導師，以便學生能夠得到 AI 的反饋和個人問題解答。因此，您如何看待這兩種範式的融合，未來五年教育將會是什麼樣子？我想每個人都感覺教育技術來臨了，但我認為目前還沒有到達真正的破壞性階段。我想，很多人正在進行不同的實驗。AI 基金擁有 AI 教學的 Coursera 教練，這實際上運行得非常良好。深度學習更加專注於教授 AI，還包括一些內建的聊天機器人。許多團隊正在試驗自動批改，哦，深度學習網站上有一個虛擬的我，如果需要的話，可以與你對話。deep learn.ai。我認為對於一些事情，比如語言學習，您知道的，像 Duolingo 這必然明顯。AI 將改變更廣泛的教育環境，而 AI 將如何變革呢，確實有大量的實驗，但我看到的關鍵學習是一些 K12 教育的應用是非常有希望的，但老實說，我看到大量的實驗，但最終的狀態仍然不明確。我相信教育會越來越個性化，但這種工作流是由虛擬化身還是文本聊天機器人，這是什麼樣的工作流呢？我覺得幾年前 AGI 就會來了，所有的一切都將變得如此容易，這只是一種炒作。實際情況是工作是非常複雜的。教師、學生和各種人獲得真正複雜的工作流，未來十年將致力於優化這些工作流，繪製出它與自主工作流的關係，而教育正是這個過程中的一個行業，在這方面的機制還不夠成熟，無法理解結局到底會是怎樣的。因此，我想我們都應該繼續努力。

### Andrew Ng <small>[32:09]</small>
謝謝你，安德魯。我的問題是，我認為 AI 大有潛力去促進良性發展，但也同樣潛藏著很多負面後果的可能性，比如加劇經濟不平等等等。我認為我們在這裡的許多初創公司將會做很多偉大的事情，這樣的產品本質上也會產生不好的後果。因此，我好奇的是，您認為我們這些 AI 建設者應該如何平衡創造的產品與 AI 產品潛在的對社會的負面影響？基本上，我們該如何在既快速推進又負責任的情況下，共同邁進？探索自己內心，如果你根本上不認為自己正在創造的產品能使大多數人過得更好，那麼就不要去做。我知道這聽起來很簡單，但在瞬間其實是非常難以做到的。但 AI 基金我們曾經殺死過多個項目，不是基於財務考量，而是基於倫理考量。我們查看了多個項目，儘管經濟案例非常確實，但我們說，你知道的，我們不想讓這種東西存在於世界上，因此基於這個理由我們就終止了它。我希望能夠促使更多人這樣做，而我對每個人都很擔心，因為我看到一些工作角色與產品管理相對的組合比重，所以盡量讓所有人能夠更好地在 AI 環境中工作。與此同時，我在我的行銷團隊中，也看到我的行銷人員，他們知道如何編碼，坦白説，他們比那些不懂得人的表現更好。因此，我們要攜手讓每個人都能夠運用 AI，這一點也是我們必須一起努力的一個重要部分。因此，我非常感謝你的工作，因為我知道這給了那些人一個機會努力去進一步理解 AI，讓他們能夠使用這項技術。 

### Andrew Ng <small>[34:37]</small>
我是你的一名大粉絲，謝謝你帶來的線上課程。你的課程使深度學習向世界更加可及。我的問題也與教育有關。隨著 AI 變得更強大和普及，似乎對於人們所能做到的和他們所感知的之間的差距在擴大。因此，你認為，教育大眾了解深度學習十分重要嗎？不僅只是讓技術人員了解，同時讓所有人更加了解 AI 實質上能做什麼和它如何運作。我認為這種知識將會擴散。深度學習，深度學習，我們希望讓每個人都有機會運用 AI。因此，我們正在不斷努力。很多人都在這方面努力。我要告訴你，我認為主要的危機可能有兩個。一是我們未能快速讓每個人都跟上，如果我們不夠快，會解決這個問題。但還有另一個危機，我認為如果你看看移動生態系統，移動電話其實不是特別有趣，而其原因在於存在兩個守 gates，Android 和 iOS。除非這些平台讓你去做某些事情，否則你便無法在移動平台上試用某些功能。我認為這限制了創新。這些 AI 的危險故事被某些企業利用，這些企業試圖去關閉開源開發者，因為一些企業願意成為大型基礎模型的衛兵。因此，我認為，誇大 AI 的安全風險，以促使監管機構通過法律，就像加州提議的 SP 1047，如果我們不幸通過，那將會設置極其繁重的治理要求，這不會使任何人更加安全，但會使開源和開放框架的發布變得非常困難。因此，造成不平等的另一種危險是，如果這些監管措施變得十分尷尬，我曾經親身見證，有些公司在與監管機構交流時提出的觀點是完全不正確的。明顯地，這些提出的論據都是有危險的，因此，如果這些監管提案通過，導致我們的資訊傳遞過程艱難，只剩下少數守門者，讓大家需要得到少數幾家公司的許可才能完全運用這些基礎模型，這會抑制在開放協議的基礎下的創新，並阻止這些資訊擴散。只要防止這類對開放源代碼和開放權限模型的侵擾成功，我們已經取得了良好的進展，但威脅仍然存在。那麼，我希望最終會對知識的擴散，讓大家都能獲得繼續發展的機會，但這場保護開源的戰役我們一直在勝利，但還是持續進行中，我們依然要不斷努力。非常感謝各位，真的是很棒的。

### Andrew Ng <small>[37:01]</small>
evals. And so the model we use week by week, you know, sometimes our engines will change it without even bothering to tell me because the eval show the new model works better. So it turns out that switching cost for foundation models is relatively low and we often architect our software. Oh, AI suite is open sourcing that my friends and I worked on to make switching easier. Um, switching cost for the orchestration platforms is a little bit harder. Uh but I find that preserving that flexibility in your choice of building blocks often let you go faster even as you're building more and more things on top of each other. Um so hope that helps. Thank you so much. In the world of education in AI, there are two paradigms mostly. So one is AI can make teachers more productive. Uh automating grading and automating homeworks. But another school of thought is that there'll be personal tutors for every student. So every student can have one tutor that gets feedback from an AI and gets personal questions from them. So how do you see these two paradigms converge and how would education look like in the next five years? I think everyone feels like a change is coming in edtech but I don't think the disruption is here yet. I think a lot of people are experimenting with different things. So you know Corsera has Corsera coach which actually works really well. Um deep learn is more focused on teaching AI also has some built-in chat bots. Um a lot of teams experiment of autograding. Oh there's an avatar with me on the deep learn website you can talk to if you want. Uh deep learn.ai. And then I think for some things like language learning with you know speak Dolingo that has become clearer some of the ways AI would transform it for the broader educational landscape the exact ways that AI would transform it I see a lot of experimentation I think what key learning which I've been doing some work with is doing is is very promising for K12 education but I think uh what I'm seeing is frankly tons of experimentation but the final end state is still not clear. I do think education will be hyperpersonalized. Uh but that workflow is an avatar, is a text chatbot, what's the workflow? I think um I feel like the hype from a couple years ago that with AGI soon and it will be all so easy. That was hype. The reality is work is complex, right? teachers, students, people do really complex workflows and for the next decade we'll be looking at the work that needs to be done and figuring out how to map it to

### Andrew Ng <small>[39:17]</small>
done and figuring out how to map it to agentic workflows and education is one of the sectors where this mapping is still underway but it's not yet mature enough to the point where the end state is clear. So I think I think we should all yeah just keep working on it. All right. Thank you so much Andrew. Thank you. Uh hey my question is I think AI uh it has a lot of great potential for good but there's also a lot of potential for bad consequences as well such as exacerbating economic inequality and things like that and I think a lot of our startups here while they'll be doing a lot of great things will also be you know just by virtue of their product be contributing to some of those negative consequences. So I was curious how do you think you know us as AI builders should kind of balance our uh product building with also the potential societal downsides of some AI products and essentially how can we uh both move fast and be responsible as you mentioned in your talk look in your heart and if fundamentally what you're building if you don't think it'll make people at large better off don't do it right I I know it sounds simple but actually really hard to do in the moment but AI fund we've killed multiple projects projects not on financial grounds but on ethical grounds where there are multiple projects we looked at the economic case is very solid but we said you know what we don't want this exist in the world and we just killed it on that basis so I hope more people will do that and then I worry about uh bring everyone with us one thing I'm seeing is um people in all sorts of job roles that are not engineering are much more productive if they know AI than if they don't and so for example on my marketing team my marketers they know how the code. Frankly, they they were running circles around the ones that don't. So, then everyone learned to code and then they got better. But I feel like um trying to bring everyone with us to make sure everyone is empowered to build with AI. That'll be an important part of what all of us do, I think. Um I'm one of your big fans and thank you for your online courses. Your courses make the deep learning like uh much more accessible to the world. And my question is also about education. uh as AI becomes more powerful and widespread, there seems to be a growing gap between what can actually do and what people perceive it. So what do you think about like is it important to educate the general public about deep learning stuff and not only like uh

### Andrew Ng <small>[41:36]</small>
learning stuff and not only like uh educate those technical people and make people understand more what really uh what AI really do and how it works. I think that knowledge will diffuse deep learn AI we want to empower everyone to build with AI. So we're working on it. Many of us work on it. I'll just tell you what I think is the main d I think there are maybe two dangers. One is if you don't bring people with us fast enough, I hope we'll solve that. There's one other danger which is um it turns out that if you look at the mobile ecosystem, mobile phones, it's actually not that interesting. And one of the reasons is there are two gatekeepers, Android and iOS. And unless they let you do certain things, you're not allowed to try certain things on mobile. And I think this, you know, hampers innovators. These dangers of AI have been used by certain businesses. They're trying to shut down open source because a number of businesses that love to be a gatekeeper to large scale foundation models. So I think hyping up dangers, supposed false dangers of AI in order to get regulators to pass laws like the proposed SP 1047 in California, which thank goodness we shut down, would have put in place really burdensome regry requirements that don't make anyone safer, but would make it really difficult for TS to release open source and open weight software. So one of the dangers to inequality as well is if these regulatory you know awful regry approaches and I've been in the room where some of these businesses said stuff to regulators that was just not true. So I think that um some of these arguments the danger is if these regulatory proposals succeed and end up siphoning regulations leaving us with a small number of gatekeepers where everyone needs the permission of a small number of companies to fine-tune the model prompt in a certain way that's what will cipher innovation and prevent the diffusion of this information to let lots of startups you know build whatever they want responsibly but the freedom to innovate so I think so long as we um prevent this line of attack on open source open weight models from succeeding and we we've made good progress but the threat is still there then I think eventually we'll get to the diffusion of knowledge and we can hopefully then bring everyone with us but this fight to protect open source we've been winning but the fight is still on and we still have to keep up that work to to protect open source thank you all very much it's wonderful thank
