<!-- summary -->
總結：賈瑞德·卡普蘭在演講中分享了有關AI發展的見解，探討了當前AI模型的訓練過程及其未來的潛力，並強調了擴大模型的重要性。他認為，隨著計算和強化學習的擴展，AI將能夠執行越來越多複雜的任務。

重點：
1. 當代AI模型的訓練分為預訓練和強化學習兩個階段，並且在這兩個階段中擴大計算能力可以顯著提升模型的性能。
2. AI系統的能力可從靈活性和執行任務的時間範圍兩個方向進行評估，越來越多的任務可在更短的時間內完成。
3. 要實現人類水平的AI，需要進一步強化模型的組織知識和記憶能力，以便能夠處理更長期的、複雜的任務。
4. 現有的AI訓練中，提升細微差別的理解和解決模糊任務的能力至關重要，以便能生成更具價值的輸出。
5. 隨着AI技術的迅速發展，積極尋找和利用AI的整合機會，以及探索能夠快速應用的領域，對未來的發展至關重要。
<!-- endsummary -->

<small>原始影片：[https://www.youtube.com/watch?v=p8Jx4qvDoSo](https://www.youtube.com/watch?v=p8Jx4qvDoSo)</small>

### Jared Kaplan <small>[00:03]</small>
大家好。我是賈瑞德·卡普蘭。我會簡單談談擴展和通往人類水平AI的道路，但我猜對於在座的觀眾來說，很多這些想法應該都很熟悉，因此我會簡短一些，然後我們會和黛安娜進行一個類似爐邊聊天的問答環節。事實上，我在AI領域工作只有大約六年的時間，之前的職業生涯大部分時間是作為理論物理學家在學術界工作。那么，我是怎麼進入AI的呢？我想簡單說一下。我為什麼開始學物理？基本上是因為我母親是一位科幻作家，我想弄清楚我們是否能夠建造超光速驅動器，而物理學是實現這個願望的途徑。我還對理解宇宙非常興奮。事物如何運作？我們周圍所見的所有事物背後的基本趨勢究竟來自何處？例如，宇宙是決定論的嗎？我們有自由意志嗎？我對所有這些問題都非常感興趣。不過幸運地是，在我作為物理學家的職業生涯中，我遇到了很多非常有趣、思考深刻的人，包括我現在經常合作的Anthropic的創始人們。我對他們所做的事情非常感興趣，也一直在關注他們。隨著我在物理學不同領域之間的轉換，從大型強子對撞機物理學、粒子物理學、宇宙學到弦理論等，我感到有些沮喪，也有些無聊。我覺得我們的進展不夠快速，很多朋友告訴我AI正變得越來越重要，但我不相信他們。我感到很懷疑。我想，AI已經研究了50年了，支持向量機(SVM)並不太令人興奮。這是我們在2005年和2009年讀書時所知道的所有信息。但我被說服了，也許AI會是一個令人興奮的研究領域。我運氣很好，認識了對的人，然後其餘的就是歷史了。所以，我接下來會談談我們當代的AI模型是如何運作的，以及擴展是如何使它們變得越來越好的。當代AI模型的訓練實際上有兩個基本階段。第一階段是預訓練，這是我們訓練AI模型來模仿人類編寫的數據、人類編寫的文本並理解這些數據背後的相關性。在這一階段，數據的質量非常復古。

### Jared Kaplan <small>[02:50]</small>
數據的質量非常復古。這其實來自於原始GPT-3模型的遊樂場。你可以看到，作為一個期刊俱樂部的演講者，你可能會讓我說某些事情。在那句話中，「大象」這個詞其實是非常不可能出現的。預訓練的作用是教導模型哪些詞語更可能跟隨其他詞語在大量文本中出現，而現在的現代模型還包括多模態數據。當代AI模型的第二階段是強化學習。這是另一個非常復古的幻燈片。它顯示了我們在2022年早期使用的原始界面，當時我們正在收集反饋數據。你在這裡看到的基本上是與非常早期的Claude版本進行對話的界面，並據人類和群眾工人的評價選擇Claude的哪個響應更好。利用這種信號，我們優化並強化被選為好的，有幫助的、誠實的和無害的行為，而對不好的行為則加以遏制。因此，訓練這些模型的核心就是學習預測下一個詞，然後進行強化學習以學習執行有用任務的能力。事實證明，這兩個訓練階段都有擴展法則。所以這是一個五六年前我們製作的圖，顯示出當你擴大AI的預訓練階段時，我們的模型在性能上會持續改善。這之所以能夠產生，正因為我提出了一個極為簡單的問題。作為物理學家，你的培訓就是這樣，你會把目光放在大局上，然後問出真正愚蠢的問題。在2010年代，我聽說大數據非常流行，因此我想知道數據應該有多大？這個問題有多重要？它能幫助多少？同樣，很多人注意到較大的AI模型性能更好。因此我們就問這個問題，這些模型表現得更好的程度到底是多少？我們運氣很好，發現了AI訓練背後實際上有非常精確且驚人的東西。這讓我們大吃一驚，因為這些美妙的趨勢與你在物理學或天文學中看到的任何事物一樣精確。這讓我們充滿信心，認為AI將會以非常可預測的方式變得越來越聰明。正如你所見

### Jared Kaplan <small>[05:40]</small>
正如你所見，早在2019年，我們就在計算、數據集大小、神經網絡規模上跨越了很多個數量級。因此，我們預期一旦你在這麼多數量級上看到某種趨勢成立，你就會預期在未來很長一段時間裡，它可能會繼續成立。因此，這成為了我認為改善AI的一個基本要素。另一個則實際上也是很早以前出現的，儘管在過去幾年中變得非常重要。你可以在AI訓練的強化學習階段看到擴展法則。一位研究人員大約四年前決定研究圍棋的擴展法則。將兩個非常知名的AI成功案例——GPT-3及其預訓練擴展和AlphaGo結合起來。這位研究員，安迪·瓊斯，當時自己獨自工作，可能只有一個GPU，在這些古老的日子裡。所以他無法研究AlphaGo，因為那很昂貴，但他能研究一個叫做Hex的簡單遊戲。因此，他製作了這個圖。當時，ELO分數的認知可能沒有那麼普遍，但所有的ELO分數實際上只是圍棋的評分。它們用來基準AI模型，以了解人類更喜歡哪一個AI模型。但當時，這僅僅是ELO分數作為圍棋評分的經典應用。他觀察到，當你訓練不同的模型去進行這個Hex遊戲，這是一個非常簡單的棋類遊戲，比圍棋簡單一點，他們的表現怎麼樣？他看到了一些顯著的直線。因此，這在科學上算是一種技能，去注意非常簡單的趨勢，而這一點我認為被忽略了。我認為人們對這種強化學習中的擴展行為關注得不夠快，但最終還是實現了。所以我們看到，基本上你可以在預訓練和強化學習中擴大計算能力，並獲得越來越好的性能。我認為這是推動AI進步的基本要素。這不是說AI研究人員真的很聰明，或者他們突然變得聰明，而是我們找到了一種非常簡單的方法來系統性地改善AI，而我們正在運行這個過程。那麼，這釋放了哪些能力呢？

### Jared Kaplan <small>[08:22]</small>
這釋放了哪些能力呢？我傾向於將AI的能力看作是兩個軸向。我認為不那麼有趣的軸向，但仍然非常重要的是AI的靈活性，即AI根據我們的需求適應的能力。因此，如果你把AlphaGo放在這個圖上，它會非常非常遠離X軸，因為儘管AlphaGo非常智能，超過任何圍棋玩家，但它只能在圍棋盤的宇宙中運作。然而，自從大型語言模型出現以來，我們在製作能夠處理人類所有模態的AI上取得了穩步進展。我覺得我們尚未擁有能夠嗅到味道的AI模型，但這可能會在未來出現。因此，當你沿著Y軸向上移動時，你將獲得能夠在世界上完成越來越多相關任務的AI系統。我認為更有趣的軸向是X軸，這是一個人完成AI模型可以執行的任務所需的時間，而隨著我們提高AI的能力，這樣的時間一直在穩步增加。這是任務的時間範圍，並且一個組織的研究人員系統地探討了這個問題，發現了另一個擴展趨勢。他們發現如果你觀察AI模型可以執行的任務的長度，它大約每7個月翻倍一次。因此，這意味著隨著AI的計算擴展和強化學習，內部新增的智能正在導致可預測的有用任務，這些AI模型能夠執行，包括越來越長的任務。因此，你可以基本上憑空想像一下這將朝哪個方向發展。在《AI 2027》中，大家就是這樣做的。這種畫面暗示著在未來幾年內，我們可能會到達一個AI模型能夠完成的任務不再僅需幾分鐘或幾小时，而是幾天、幾週、幾個月甚至幾年。不久，我們想像中的AI模型或數百萬個AI模型將能夠完成整個人類組織的工作。他們將能夠完成整個科學界目前所做的工作。數學或理論物理學的一個好處是，你可以僅通過思考來取得進展。因此，妳可以想像AI系統共同工作，迅速完成理論物理學社區在50年中所取得的進展。那麼，如果這種擴展的畫面能讓我們走得這麼遠，還剩下什麼呢？

### Jared Kaplan <small>[11:15]</small>
如果這種擴展的畫面能讓我們走得這麼遠，還剩下什麼呢？我認為，要普遍解鎖人類水平AI，仍然相對簡單。其中一個最重要的要素是相關的組織知識。因此，我們需要訓練AI模型，讓它們不僅僅是空白開端，還能學會在公司、組織和政府中工作，好像它們擁有在那裡工作多年的人所具備的上下文。因此，我認為AI模型需要能夠處理知識，還需要記憶。如果記憶不是知識，那麼記憶究竟是什麼呢？我的區分在於，隨著你完成一個需要非常長時間的任務，你需要跟蹤自己在特定任務上的進展，需要建立相關的記憶，並且你需要能夠使用它們。這是我們已經開始融入Claude 4中的一件事，我認為這會變得越來越重要。第三個我們需要改進的要素，我們也在努力進步的是監管。即AI模型理解細微差異以及解決艱難模糊任務的能力。目前很容易看到進展的爆炸，我們訓練AI模型使它們能夠寫出通過測試的代碼或正確回答數學問題，因為什麼是正確，什麼是錯誤，這些都非常明確。因此，利用強化學習使AI模型在這類任務中更加出色是非常容易的。但我們需要的並且正在開發的，是能夠幫助我們生成更細致的獎勵信號的AI模型，以便我們可以利用強化學習完成類似講好笑話、寫好詩和在研究中有好品味的任務。至於我們需要的其他要素，我認為這些要素更簡單。我們顯然需要訓練AI模型去執行更加複雜的任務。我們需要在Y軸上從文本模型提升到多模態模型再到機器人。並且我預計在接下來的幾年裡，當將這些不同的領域與擴展結合時，將會看到不斷的增長。因此，我們應該如何為這個未來的可能性進行準備呢？我認為有幾件事情我總是建議。首先，我認為建造那些尚未完全成功的事物是非常好的主意。這可能總是個好主意。我們永遠希望保持雄心，但我認為具體對於現在的AI模型來說，取得進展非常迅速。

### Jared Kaplan <small>[14:01]</small>
取得進展非常迅速。我想這種趨勢會持續下去。這意味著如果你建造一個尚未完全成功的產品，因為Claude 4仍然有點愚蠢，你可以預期會有Claude 5出現，而這將使該產品運作並提供大量價值。因此，我認為這是我總是建議的，即在AI能達到的邊界進行實驗，因為這些邊界正在迅速變化。下一點是，我認為AI將對整合AI非常有幫助。我認為AI真正的主要瓶頸在於發展如此迅速，以至於我們沒有時間將其整合到產品、公司以及我們所做的一切事物中進入科學。因此，我認為，要加速這一過程，我認為利用AI進行AI整合將非常有價值。最後，我的意思是，這對於這個群體來說可能顯而易見，但我認為弄清楚AI可能在何處快速採用是關鍵。我們看到編程領域的AI整合正在激增。有很多原因解釋為什麼軟體工程是一個良好的AI應用場景，我想最大的問題就是，接下來會是什麼？有什麼能像軟體工程一樣快速發展的？我當然不知道答案，但希望你能發現。那麼，演講內容就到這裡。我想邀請黛安娜上台進行交流。>> YC的下一個批次現在正在接受申請。你有創業的想法嗎？請申請ycombinator.com/apply。申請從未太早，填寫申請將升級你的想法。好吧，回到視頻。那真是一場精彩的演講，談到了所有的擴展法則，最近Anthropic剛剛推出的Claude 4。這是全新可用的。好奇的是，隨著所有這些模型釋放的持續疊加，未來12個月內可能實現什麼變化？

### Jared Kaplan <small>[16:46]</small>
這是因為如果在12個月內沒有更好的模型出現，我們可能會面臨問題。但是，我想說與Claude 4有關幾件事情。我認為使用Claude 3.7時，它在編程方面已經非常令人興奮，但我認為每個人都注意到，3.7有時會顯得過於急切。它真的很想讓你的測試通過。因此，它會做出一些你不太想要的事情，比如很多的try except等。因此，對於Claude 4，我認為我們已經提高了模型作為代理者的能力，特別是在編程方面，以及在很多其他方面，比如搜索、各種應用。我們也改善了它的監督能力，我在演講中提到的那種監督，以便它可以遵循你的指示並希望在代碼質量上有所改進。我認為我們還改善了它的能力，讓它保存和存儲記憶，我們希望人們能利用這一點，因為Claude 4能夠在非常複雜的任務中打破上下文上限，但也能夠將記憶存儲為文件或記錄，按需檢索，以便在眾多上下文窗格中持續進行工作。但我想最後一點是，擴展法則描繪出的畫面是逐步進步的。因此，你會看到Claude在每次釋放中在各種不同方面穩步變得更好。我認為擴展確實表明了一種平滑的趨勢，朝著我預期的人類水平AI或AGI的方向發展。>>是否有一些特殊的功能會讓在座的觀眾興奮？在新API上，你能給大家一些內幕消息，讓大家知道他們會愛上什麼？

### Jared Kaplan <small>[19:21]</small>
我認為我最期待的事情是解鎖記憶，以便能夠處理越來越長的任務。隨著時間的推移，我們將看到Claude作為一個合作者，能夠承擔越來越大塊的工作。這正符合你的觀點，即所有這些未來模型將能夠完成越來越大的任務。目前，在這一點上，它們已經能夠在幾小時內完成任務。>> 是的，我想現在的確是一個不太精確的度量，但我認為如果你觀察軟體工程任務，我認為計量標準實際上衡量了人們完成各種任務所需的時間，現在的確是在數小時的時間範圍內。我認為，隨著人們與AI的協同工作，那些懷疑AI的人會合理地指出，AI會犯很多愚蠢的錯誤。它可以做一些絕對出色的事情，讓你驚訝，但它也會犯下一些基本的錯誤。我認為AI的一個基本特徵是它的智慧與人類智慧的形態是不同的。AI有很多事情是我無法完成的，但是我至少可以判斷它們是否正確。我認為對於AI來說，判斷和生成的能力更接近，這意味著我認為人們在與AI互動中的主要角色是管理者，以檢查工作的正確性。>> 有趣的是，我們在YC的批次中觀察到的情況，很多公司在選擇產品時，仍然以副駕駛的形式銷售產品，這意味著你仍然需要最後一位人類的批准，客戶的回覆才會發送出去。但從春季批次開始，許多AI模型已經能夠端到端地執行任務，這真是了不起的，創業者現在正直接推出完整工作流的替代品。你看到這一點如何轉化為你希望觀眾所建立的內容？我認為有很多可能性。基本上，這是一個問題，成功或性能接受到什麼程度。有些任務，獲得70%是可以接受的，而有些任務則需要99.9%才能部署。我實話實說，我認為在70-80%夠用的用例上構建會更有趣，因為這樣你實際上可以接觸到AI的能力邊界。但我認為，我們也在不斷提高穩定性，因此，我認為我們將看到更多的這些任務。現在，人工與AI的協作將成為最有趣的地方，因為對於最先進的任務，你真的需要人類在回路中。但我確信，從長遠來看，將會有越來越多的任務可以完全自動化。

### Jared Kaplan <small>[22:07]</small>
你能更多地談談你認為人與AI協同工作將會是什麼樣的世界嗎？因為Dario的《愛與恩典機器》的散文中描繪了一個非常樂觀的畫面，我們如何達到這樣的情景呢？我認為我們已經可以看到一些進展。因此，至少當我與生物醫學研究的工作者交談時，我相信在正確的協調下，可以利用前沿AI模型產生有趣和有價值的見解，例如用於藥物發現。因此，我認為這已經開始發生。我猜我思考其中一個方面是，某些智力需要很深，而某些智力卻需要很廣泛。例如，在數學中，你可以專注於花十年來證明一個定理，例如三號假設或費馬最後定理。我認為這解決了一個非常具體且非常困難的問題。科學的許多領域中，尤其是生物學、心理學和歷史等領域，將來自許多不同領域的大量信息彙集在一起才是關鍵。我認為AI模型在預訓練階段能吸納整個人類文明的知識。因此，我懷疑在使用AI的特性方面，尤其在涉及大量知識的情境中，將會有許多待挖掘的寶藏。從某種意義上說，我們正在促進AI在一些更深層次的任務如複雜編程問題和艱深數學問題上的表現進步，但我懷疑在那些需要將知識整合的領域中，至少沒有一個人類專家具備的地方那種智能會非常有用。因此，我希望將來能看到更多利用AI的知識廣度這方面的能力。至於具體如何展開，我真的不知道，預測未來是非常困難的。擴展法則為預測未來提供了一種方法，這意味著這一趨勢將持續下去。我希望在長期中，我們所看到的許多趨勢將會持續下去。我的意思是，經濟、GDP等這些趨勢都是非常可靠的未來指標。但我認為具體實施細節將很難預測。>> 是否有具體的領域你認為更多的建設者可以深入並與這些新模型合作？我知道在編程任務方面已經做了很多，但還有什麼新任務正在當前模型的基礎上開啟新局面？

### Jared Kaplan <small>[24:49]</small>
我來自研究背景而非商業背景，所以我不確定自己能否說出非常深刻的見解，但我認為總體而言，只要涉及大量技能，並且大部分任務主要是在電腦前與數據互動了解的地方都是一片綠地。我認為在財務領域使用Excel電子表格的人也是如此。我預期法律領域也是如此，但或許法律領域受更多監管，需要專業知識的認可。但我認為所有這些領域很可能都是綠地。我還提到一點就是我們如何將AI整合進現有業務中。我認為當電力出現時，經歷了一定的採用周期，最簡單的使用電力的方式未必是最佳的。你不僅要將蒸汽機更換為電動馬達，而是要重新設計工廠的工作方式。我認為在經濟的各個部分內，快速利用AI進行整合將是非常有利的。我另一個問題是你作為物理學家有著廣泛的訓練，你是第一批真正觀察到擴展法則趨勢的人，這或許來自於你作為物理學家的訓練，看到自然界中所有自然出現的指數特徵。這樣的訓練對於你能在全球最好的AI研究中表現如何起到了什麼影響？我認為從物理的觀點看，查找最大的圖景和宏觀趨勢然後盡可能的精確化是一個很有用的手段。所以我記得遇到一些出色的AI研究者，他們會說類似「學習正在以指數速度收斂」的話，而我會問一些愚蠢的問題，比如「你確定這是指數的嗎？它可以是冪次法則嗎？是二次的嗎？這是怎樣收斂的？」這確實是個很愚蠢且簡單的問題，但我認為這裡面有許多可以思考的空間，並且可能仍然有許多機會去努力讓你看到的大趨勢越來越精確，因為這樣能夠給你帶來大量的工具，幫助你問自己，如何真正去推動事物的發展。我覺得用擴展法則的這個神聖指引來找到更好的斜率將是非常重要的，因為這意味著當你投入更多計算力時，你將獲得比其他AI開發者更大的優勢。但在你不確定所看到的趨勢是什麼之前，基本上你並不會知道有太多的手段去打敗它，並且也不會系統地知道你是否正在實現這個目標。因此，我覺得這些是我認為我所用的工具。並不僅僅是應用量子場論於AI。這樣有點過於具體。但是，有沒有具體的物理啟發或啟發式做法，比如重整化、對稱性，能再很方便的保持這種趨勢或測量這一趨勢？

### Jared Kaplan <small>[27:35]</small>
你會觀察到，如果你查看AI模型，他們都是巨大的。神經網絡是巨大的。它們有數十億現在甚至數萬億的參數。這意味著它們是由大型矩陣組成的。基本上研究這些AI模型的近似法則，特別是神經網絡組成的矩陣都是很有幫助的，但這其實在物理學和數學中也早就被發現了。這是非常有用的一個方面。此外，我認為精簡、重整化等這些物理中使用的工具是非常重要的。我認為AI的發展過於年輕，在某種意義上，AI可能只有10到15年的歷史。因此這是一個全新且極具潛力的領域。許多最基本的問題，比如可解釋性問題，AI模型真正如何運作的問題，還未解決。因此，我認為在這一層面上仍有很多學習的餘地，而不僅僅是應用非常高端的技術。你對於可解釋性的哪些物理工具有所應用嗎？我會說可解釋性更像是生物學或神經科學。這是比較相關的工具。那裡有相對多一點的數學工具。但我認為這更像是試圖理解大腦的特徵。與神經科學相比，你在AI中獲得的利益在於你能夠真正測量一切。在大腦中，你無法測量每個神經元的活動和軸突，但在AI中你可以做到。因此，你擁有更多的數據來進行逆向工程，以了解AI模型的運作機制。>> 現在有關擴展法則的問題，它們在五個數量級上持續有效，這點相當驚人。我這是一個反向問題，但有什麼實證跡象會讓你相信這些曲線正在改變，或者我們可能偏離曲線？

### Jared Kaplan <small>[30:09]</small>
可能偏離曲線？我認為這是一個非常難的問題，因為我主要利用擴展法則來診斷AI的訓練是否出現問題。因此，我的第一直覺是，如果擴展法則無效，可能是因為我們在某種程度上搞砸了AI的訓練，也許我們弄錯了神經網絡的架構，或者訓練中出現了某些看不見的瓶頸，或者我們所使用的算法在精度上存在某些問題。因此說服我，擴展法則不再有效會需要很多的證據。至少以我過去五年的經驗來看，當擴展法則似乎失效時，反而是因為我們的做法不對。>> 很有趣。接下來我想談一些非常具體的內容，這與所需的計算能力密切相關，若要繼續沿著這條曲線發展，會發生什麼？隨著計算變得越來越稀缺，你會進入精度的更低階梯嗎？你會探討FP4等技術還是會考慮類似三元表示法等技術？你對此有何看法？是的，我認為目前AI實際上效率較低，因為AI中有很大的價值。因此，解鎖最具能力的前沿模型有著巨大的價值。因此，像Anthropic和其他公司一樣，正在盡可能快速地推進，既提高AI訓練的效率，也提高AI推理的效率，同時解鎖前沿能力。但大多數焦點都在於解鎖前沿技術。隨著AI變得越來越普遍，我認為我們會驚人地降低推理和訓練的成本，近幾年來，算法和計算能力的擴展提升大致為3到10倍，而每年的推理效率也在逐步提高。我想這是玩笑話——我們會將計算機帶回二進制。因此，我預計會出現更低的精度作為提高推理效率的多種途徑之一。但我們現在仍然處於AI開發的高度不平衡中。AI正在迅速改進，變化也在發生，而且我們尚未充分發揮目前模型的潛力，但我們正在解鎖越來越多的能力。因此，我認為當AI不再快速發展的時候，平衡狀況可能會是AI非常便宜，但有點難以預測我們是否會到達那個境界。也許AI會持續迅速升級，因此智能的提升會解鎖更多的種種可能性，我們可能會繼續專注於此，而不是轉向將精度降低到FP2的領域。

### Jared Kaplan <small>[32:51]</small>
這絕對是矛盾的悖論，因為隨著智慧變得越來越強，人們會希望得到更多，而不是降低成本，這很諷刺。>> 是的，絕對是的，我認為，這絕對是我們所看到的一種情況，AI在某個特定點變得足夠可及。也就是說，隨著AI系統變得越來越強大，能夠完成越來越多的工作，值得為崎嶇的前沿能力付出代價。我一直有一個問題，是否所有的價值都在前沿技術上，或者是否還有其他價值存在於不那麼強大的低價系統中。我認為時間範圍的概念是思考這個問題的一種方式。我相信，你可以進行許多非常簡單的細碎任務，但使用一個可以端到端完成非常複雜任務的AI模型會更方便，而不需要我們這些人類去協調一個不那麼聰明的模型，將任務細分為非常小的片段並加以組合。因此，我預計很多價值將來自於最強大的模型，但我可能錯了。它可能視情況而定，並且可能真的取決於AI整合者的能力，他們能夠高效利用AI。>> 你會給這個聽眾什麼建議？這裡的每個人都早早開始自己的事業，潛力十足，在將來所有模型變得如此出色的情況下，如何保持自身的相關性呢？每個人應該在什麼事情上特別擅長？我認為，正如我提到的，了解這些模型的運作原理，能夠高效地利用和整合它們是非常重要的。我認為在前沿領域中構建也是有價值的。我不確定，或許我們可以交給觀眾進行問題詢問。

### Jared Kaplan <small>[35:23]</small>
或許我們可以交給觀眾進行問題詢問。>> 讓我們將問題交給觀眾。>> 我有一個關於擴展法則的快速問題。你展示了許多擴展法則是線性地，算是我們計算的指數增長，但在你最後的幻燈片中，你卻表達出你預期會突然實現指數增長，像是我們節省了多少時間。我想問你，為什麼在這個圖表上，我們會突然從線性變成了指數？謝謝。>> 這是一個很好的問題，我不知道。我認為，一種說法是，計算的擴展法則的發現相對於我們總體的發現而言較為經驗——簡單來說，这样的想法是，通过一個模型在執行過程中多次修正，而不需要有大量的上下文。實際上，我認為模型的推進伴隨着其自我修正的能力。當你進行計畫佈置時，實際上計劃並不完美，因此通過修正，你可能會在大概的範圍上提高一半的計劃執行能力。這是一個基於相對適度改善的方法。雖然這只是一個直覺而已，但培養這種自我修正的能力在實踐中相當有價值。或許更具體的思考圍繞著這種觀察，但可能我們需要進一步的模型來了解為什麼該趨勢成立，這可能是說不準的。

### Jared Kaplan <small>[37:42]</small>
是的，我還有一個問題。這是我感到榮幸的問題。在增加時間範圍的前提下，我覺得我的神經網絡思考模型相對簡單。如果我們想讓它們做某事，就需要訓練相關數據。假如我們想增加時間邊界，我們必須逐漸獲取驗證信號。我認為有一種方法可以實現這一點，就是產品的方式。譬如說使用Claude模型進行驗證，通過驗證關聯來逐步改善模型。那么在其他領域，比如說我們是否在攻擊場景時只是依賴於標籤來縮短這些並增強AGI的準備？還是有更好地方法呢？這是一個很好的問題。在我認為，當懷疑者問我，我為何相信我們能夠對AI進行如此強大的擴展，歸咎於你的所述。實際上這是一個非常操作性的路徑，你的模型可以通過不斷進行各種複雜任務的訓練，不斷增強其作業的能力。因此，我認為這是AI進步的最壞情況。綜合回顧的結論到此，但我相信有人會充分利用與AI的協作，AI不僅能夠控制問題，甚至能夠用戶的例子進行指導。所以我相信這將使訓練長期的任務變得更有效，並且我認為我們已經在這方面邁出了相當的步伐。

### Jared Kaplan <small>[40:09]</small>
這樣就結束了最後一個問題。非常感謝！」
