<!-- summary -->
- **從物理學到 AI**：Jared Kaplan 的職業生涯始於理論物理學，他希望理解宇宙的基本法則。然而，他對物理學進展的速度感到沮喪，並被朋友們說服，AI 領域正在發生巨變，於是他轉向了 AI 研究，並最終共同創辦了 Anthropic。
- **擴展定律（Scaling Laws）**：他詳細闡述了 AI 領域的「擴展定律」，即模型的性能（以損失函數 loss 為指標）會隨著運算量、數據集大小和模型參數數量的增加而可預測地、平滑地提升。這就像物理學中的定律一樣，為建立更強大的 AI 模型提供了清晰的路徑。
- **可預測的突破**：擴展定律不僅能預測性能的提升，甚至能預測「湧現能力」（emergent abilities）的出現。例如，可以預測在達到某個規模後，模型將能學會做加法。這意味著 AI 的進步在很大程度上是可預測的，只要有足夠的運算資源。
- **通往人類水平 AI 之路**：他認為，通往人類水平 AI 的道路就是持續擴展。雖然目前模型的某些能力（如推理）仍落後於人類，但他相信隨著模型規模的持續擴大，這些差距將被彌補。他將 AI 的發展比作工業革命，認為我們正處於一個將從根本上改變世界的轉型期。
- **AI 的社會影響**：他承認 AI 可能帶來的社會風險，如加劇不平等或被用於惡意目的。但他更樂觀地認為，AI 也能帶來巨大的好處，例如加速科學發現、應對氣候變遷等。他認為，確保 AI 朝著有益的方向發展，是整個領域需要共同面對的挑戰。
<!-- endsummary -->

<small>原始影片：[https://www.youtube.com/watch?v=p8Jx4qvDoSo](https://www.youtube.com/watch?v=p8Jx4qvDoSo)</small>

### 中文翻譯

**Jared Kaplan:** [00:00:01]
大家好。嗯，我是 Jared Kaplan。我將簡要地談談擴展（scaling）以及通往人類水平 AI 的道路，但我的猜測是，對於在座的各位來說，很多這些想法都相當熟悉，所以我會講得簡短一些，然後我們將與 Diana 進行一場爐邊對談式的問答。

[00:00:20]
我實際上只從事 AI 工作大約六年。在此之前，我的大部分職業生涯是一名理論物理學家，在學術界工作。那麼，我是如何進入 AI 領域的呢？嗯，我，我想簡短地說。我為什麼從物理學開始？基本上是因為我媽媽是一位科幻小說作家，我想弄清楚我們是否能建造一個超光速驅動器，而物理學是實現這一點的方法。嗯，我也對僅僅是理解宇宙非常興奮。事物是如何運作的？那些構成我們周遭一切基礎的最大趨勢，它們都從何而來？例如，宇宙是決定論的嗎？我們有自由意志嗎？我對所有這些問題都非常非常感興趣。

[00:01:08]
但幸運的是，在我的物理學家生涯中，我遇到了很多非常非常有趣、非常有深度的人，包括我現在一直與之共事的 Anthropic 的許多創辦人。嗯，我對他們正在做的事情非常感興趣，並一直保持關注。當我從物理學的不同學科領域，從大型強子對撞機物理學、粒子物理學、宇宙學、弦論，嗯，等等，轉移時，我感到有點沮喪，有點無聊。我覺得我們進展得不夠快。我的很多朋友告訴我，AI 正在成為一件非常大的事情。嗯，我不相信他們。我非常懷疑。我想，嗯，AI，人們已經研究了 50 年了。支持向量機（SVM）沒那麼令人興奮。嗯，那是在 2005 年、2009 年我在學校時我們所知道的一切。但我被說服了，也許 AI 會是一個令人興奮的工作領域。嗯，我，我非常幸運…

[00:02:10]
我非常幸運能夠在正確的時間、正確的地點，與正確的人在一起，他們能夠真正地向我解釋正在發生的事情，並說服我，這將是一件大事。所以我轉行了。我離開了物理學，加入了 Anthropic 的前身，也就是 OpenAI，然後我們一起創辦了 Anthropic。我對此感到非常興奮。我認為我們正處於一個將從根本上改變世界的轉型期，就像工業革命一樣。我認為我們有機會做一些真正了不起的事情。

**主持人 (Diana):** [00:02:45]
太棒了。所以你提到了擴展定律。你能為我們解釋一下那是什麼嗎？

**Jared Kaplan:** [00:02:50]
是的。所以，擴展定律是我們在 2020 年發現的一系列經驗性結果。我們發現，當你訓練這些大型語言模型時，它們的性能會隨著你投入的運算量、數據集的大小以及模型參數的數量而可預測地提升。這是一個非常平滑、可預測的關係。你可以把它畫在一張對數-對數圖上，你會得到一條直線。這意味著，如果你知道你在較小規模上的表現，你就可以推斷出你在更大規模上的表現。這非常強大，因為它給了我們一條通往更強大 AI 的清晰路徑。

**主持人 (Diana):** [00:03:30]
所以，這基本上是說，只要我們投入更多的運算和數據，我們就能得到更好的模型？

**Jared Kaplan:** [00:03:35]
完全正確。這就是擴展定律的核心思想。當然，還有很多細節。你需要正確的架構，你需要正確的訓練過程。但總體來說，這是一個非常簡單而強大的想法。它告訴我們，我們不需要一些神秘的、未知的演算法突破。我們只需要擴展我們現有的方法。

**主持人 (Diana):** [00:04:00]
這是否意味著我們最終會達到人類水平的 AI？

**Jared Kaplan:** [00:04:05]
我認為是的。我認為通往人類水平 AI 的道路就是持續擴展。當然，我們還沒有到那一步。我們目前的模型在某些方面仍然不如人類，比如常識推理和對世界的深刻理解。但我相信，隨著我們繼續擴展模型，這些差距將會被彌補。我認為我們正走在一條通往真正通用智慧的道路上。

**主持人 (Diana):** [00:04:35]
你對 AI 的潛在風險有什麼看法？

**Jared Kaplan:** [00:04:38]
我認為這是一個非常重要的問題。我認為我們需要非常認真地對待 AI 的風險。我認為有兩種主要的風險。第一種是意外風險，也就是我們無意中創造了一個對人類有害的 AI。第二種是惡意使用風險，也就是有人故意使用 AI 來作惡。我認為我們需要同時應對這兩種風險。

[00:05:05]
在 Anthropic，我們非常專注於 AI 安全。我們正在努力開發能夠與人類價值觀保持一致的 AI。我們正在努力開發能夠被人類理解和控制的 AI。我們認為，這是確保 AI 朝著有益方向發展的唯一途徑。

**主持人 (Diana):** [00:05:25]
你對 AI 的未來感到興奮嗎？

**Jared Kaplan:** [00:05:28]
我非常興奮。我認為我們正處於人類歷史上最激動人心的時刻之一。我認為我們有機會利用 AI 來解決一些世界上最緊迫的問題，比如氣候變遷、疾病和貧困。我認為我們有機會利用 AI 來創造一個更加繁榮、更加公平、更加永續的世界。我很高興能成為其中的一份子。