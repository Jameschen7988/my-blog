<!-- summary -->
總結：在智慧科技迅猛發展的時代，埃隆·馬斯克分享了他對未來的看法和自己創業的歷程。他強調人工智慧的潛力，以及在創新過程中面對挑戰的重要性。

重點：
1. 埃隆·馬斯克認為，我們距離實現數位超智慧非常接近，隨著科技進步，未來的經濟潛力將是當前的數千倍。
2. 在創業初期，馬斯克曾面臨多種選擇，最終選擇了投入互聯網技術，並創辦了Zip 2，最終賣出取得成功。
3. 他提到最初對創辦公司的預期並不高，但因為對技術的熱情及對限制的反感，使他努力追求創新。
4. 馬斯克警告，人工智慧的發展可能對經濟和社會帶來深遠影響，企業應對其潛在的挑戰有所準備。
5. 他強調面對消費者的直觀需求和技術開發的重要性，並呼籲創業者要堅持自己的理想，尋求突破傳統的創新。
<!-- endsummary -->

<small>原始影片：[https://www.youtube.com/watch?v=cFIlta1GkiE](https://www.youtube.com/watch?v=cFIlta1GkiE)</small>

### Elon Musk <small>[00:02]</small>
我們正處於智慧大爆炸的非常早期階段。成為一種多星球物種大大延長了文明、意識或智慧（無論是生物的還是數位的）的可能壽命。我認為我們距離數位超智慧相當接近。如果今年不會實現，明年肯定會實現。 [音樂] 請為埃隆·馬斯克熱烈鼓掌。 [掌聲] 埃隆，歡迎來到人工智慧創業學校。我們今天能夠有你在這裡真是非常幸運。呃，謝謝你邀請我。因此，從SpaceX、特斯拉、神經聯網、XAI等公司來看，你的生活中是否有過這樣的時刻──在一切之前，讓你感受到必須建造一些偉大的東西？是什麼讓你轉變了思維？呃，好吧，我最初並不認為我會建造出什麼偉大的東西。我想嘗試建造一些有用的東西，但我並不認為我會建造任何特別偉大的東西。如果從概率上來說，這似乎不太可能，但我至少想試試。所以你正在與一群都是技術工程師的人交談，這些人當中常常有一些在人工智慧領域非常傑出的研究人員。好吧，我認為我們應該，我喜歡工程師這個稱謂比研究者這個稱謂更好。我想，如果有某種基本的算法突破那是研究，但否則這就是工程。也許我們可以從很久以前開始。我是說，當你這是個充滿18到25歲年輕人的房間的時候。嗯，這個年齡段偏向年輕，因為創始人群體越來越年輕。呃，你能夠把自己帶回到他們的立場上嗎？當你18或19歲，學習編碼，甚至為Zip 2提出第一個想法時，你是什麼樣的感覺？對，我在1995年面臨了一個選擇，或是進行研究生學習博士學位在斯坦福大學的材料科學，實際上是研究超電容器的潛在用途以解決電動車的續航問題，或是嘗試在這個大多數人從未聽說過的互聯網事物中做一些事情。我和我的教授比爾·尼克斯談過這件事，我說，呃，我能否推遲一個學期，因為這可能會失敗，我需要回到學校。然後他說，這可能是我們最後一次交談，他是對的。然而，我認為事情最有可能會失敗，而不是成功。而在1995年，我寫下了，基本上是第一個或者接近第一個的網路白頁和網路黃頁。

### Elon Musk <small>[03:08]</small>
嗯，我基本上寫下了第一個或接近第一個的地圖方向及網路白頁和網路黃頁。嗯，我是親自寫的，甚至沒有使用網頁伺服器。我只是直接讀取端口，因為我無法負擔，無法負擔T1的費用。嗯，最初的辦公室位於帕洛阿爾托的謝爾曼大道。樓下有一家ISP。因此，我鑽了一個洞通過地板，然後直接把網路線接到了ISP。嗯，我的兄弟和另一位共同創辦人格雷格·卡里加入了我，他已經去世了。呃，那時候我們甚至無法負擔一個住的地方，因為辦公室每月500美元，所以我們就住在辦公室裡，然後在佩奇米爾的YMCA洗澡。嗯，因此，我們我想我們最後成立了一家相當有用的公司，最初的Zip 2。呃，我們確實開發了很多真正優秀的軟體技術，但我們在某種程度上被傳統媒體公司所束縛，那些如《紐約時報》的投資者和客戶，以及董事會成員。他們不斷希望用我們的軟體以合乎邏輯的方式使用，但這些方式並不合適。所以，我想要直接面對消費者。總之，長話短說，過多地沉迷於Zip 2，但我實際上只是想在互聯網上做一些有用的事情。因為我有兩個選擇：要麼攻讀博士，讓人們建設互聯網；要麼在某種小的方式上幫助建設互聯網。我想，哎，我想我總可以嘗試失敗，然後再回去讀研究生。然而，最後這當然是相當成功的。賣了大約3億美元，對當時來說是很多。這些天，AI初創公司的最低出價大約是十億美元。嗯，現在有很多獨角獸，這就像是一群獨角獸，你知道，獨角獸是一種十億美元的情況。自那以後通脹了很多，所以實際上比以前多了許多錢。是的。我是說，1995年你可能能用五分錢買一個漢堡。雖然不是完全，但是，嗯，是的，確實發生了很多的通脹。嗯，但，呃，人工智慧的炒作水平，如你所見，是相當強烈的。嗯，你知道，你會看到，呃，一些小於一年的公司有時獲得十億或數十億的估值。嗯，我想這可能會產生結果，並且在某些情況下會發生。然而，看到一些這些估值真是令人目瞪口呆。

### Elon Musk <small>[06:05]</small>
嗯，是的，你覺得呢？我是說，我個人是相當看好的。我很看好，老實說。所以，我認為在這個房間裡的人將創造出許多價值，呃，你知道，全球十億人應該在使用這些東西。呃，我們甚至還只是表面上捉摸到它。我很喜歡互聯網的故事，因為即使在那時，你知道你和這個房間裡的人非常相似，那時所有傳統媒體公司的CEO都看著你，認為你是了解互聯網的人，而很大一部分不理解人工智慧正在發生什麼的企業界也將目光投向這個房間的人。呃，聽起來你的確觸及到一些具體的教訓，一個是不要放棄董事會控制，或者小心制訂一個很好的律師。我想在我的第一份初創公司中，最大的錯誤是讓傳統媒體公司擁有過多的股東和董事會控制，然後他們必然會從傳統媒體的角度看待事情，因此會讓你做出看似對他們明智的事情，但實際上對新技術並不合理。呃，我知道我應該指出，我一開始其實並不打算創辦公司。我是說，我試圖去Netscape找工作。呃，我把我的履歷寄給Netscape，馬克·安德森知道這件事情。呃，但是我不認為他看過我的履歷，然後沒有人回復。所以，呃然後我試著去Netscape的大廳晃悠，看能否碰到某人，但我對任何人都太害羞了，因此我想，天啊，這未免也太可笑了。於是我決定自己寫軟體看看會怎樣。所以，這其實不是出於想創辦公司。我只是想參與建設互聯網的過程。呃，由於我無法在互聯網公司找到工作，所以我只能創辦一家互聯網公司。無論如何。是的。我是說，從人工智慧將會如此深刻地改變未來的情況來看，很難想像到底有多少，但你知道，經濟假設我們不會遇到問題，並且像人工智慧不會摧毀我們所有的自己，那麼你最終會看到一個經濟體，這不會只是比當前的經濟多10倍。最終，如果我們成為說。

### Elon Musk <small>[08:46]</small>
如果我們成為說，或者我們的未來機器後裔，或者大多數機器後裔成為像一种規模2的文明或更先進的文明，我們討論的就是一個比今天的經濟體大數千倍甚至數百萬倍的經濟體。所以，呃，是的，我是說，當我在華盛頓特區時，感覺到有點像，哎，你知道的，像擺脫浪費和欺詐，這是一個有趣的旁支任務，呃，這可算是旁支任務。然而，呃，我必須回到主要任務上。是的，我得回到主要任務上。呃，所以回到主要任務。因此，我感覺有點像，你知道的，修復政府就像，哎，沙灘髒了，上面有針和糞便和垃圾，而你想要清理沙灘，但還有一場一千英尺高的海浪即將襲來，這是一個人工智慧的海嘯。如果你要清理沙灘，那它到底有多重要呢？不那麼重要。哦，我們很高興你回到主要任務上。這是非常重要的。是的，回到主要任務上。呃，建造技術，這是我喜歡做的事情。呃，這麼多噪音。像在政治中的信號與噪音比率是可怕的。所以，呃，我的意思是，我住在舊金山，所以你不需要再告訴我第二次。是的，華盛頓特區的情況就像，呃，我想這裡面Ⅹ有所有政治，但如果你試圖建造火箭或汽車，或者你試圖有一個可靠編譯運行的軟體，那麼你必須成為最大限度地追求真相，否則你的軟體或硬體就不會工作。呃，像數學和物理都是嚴格的裁判。我習慣在一個最大限度追求真理的環境中，這絕對不是政治。呃，因此，我對回到，如今的技術感到高興，我想我有些好奇再次回到Zip 2的那一刻。你獲得了幾千萬美元的回報，或是說你獲得了幾千萬美元的退出。我是說，我得到了2000萬美元，對吧？好的。所以，你至少解決了資金問題。呃，而你幾乎將這筆錢全數投入到X.com，如你所說，像是幾乎將所有的 chips放在桌上。呃，是的，不是每個人都這樣做。房間裡的許多人將不得不做出這個決定。到底是什麼驅使你再次進入這個領域？好吧，我覺得，和Zip 2一起，我們曾經建立了了不起的技術，但它從未被真正使用。

### Elon Musk <small>[11:31]</small>
呃，你知道，我想至少從我的觀點看，我們的技術比雅虎或任何其他的技術要更好，但是被我們的客戶所約束。因此，我想做一些不受我們的客戶約束的事情，直接面向消費者，這最後造成了像x.com和PayPal這樣的實體。本質上，x.com與Confinity合併，形成了PayPal，而結果似乎，PayPal對於21世紀來說創造了更多的公司，可能比任何其他的東西更多。也就是說，Confinity和X.com的結合產生了許多才華橫溢的人。因此，我只是想，也覺得我們在Zip 2的發展被限制了一些，那就是，假設我們的翅膀沒有被束縛，去面對消費者，這就是最終的PayPal。然而，說到我收到了那張2000萬美元的支票，呃，來自Zip 2的分紅。當時我與四名室友住在同一棟房子中。呃，我在銀行中大約有1萬美元，然後這張支票到了郵件中，而我銀行的餘額從1萬美元增加到2000萬美元。呃，你會想：“好吧。”嗯，還是得為此繳納稅款等等，但我最終幾乎將這筆款項全數投入到x.com之中，如你所說，幾乎將所有的 chips留在桌上。呃，然後在PayPal之後，我想，嗯，我有點好奇，為什麼我們還沒有送任何人去火星。呃，我登上NASA網站查看我們何時會送人去火星，但那裡沒有日期。我以為這只是網站上找不到資料而已。然而，實際上根本沒有實際計劃要送人去火星。因此，你知道，我來，這是一個很長的故事，因此我不想佔用太多時間，嗯，我想我們都在認真傾聽。于是，我實際上和我的朋友Doris在長島高速公路上，我們大學時的同班同學，而Doris問我，PayPal後我會做什麼，我回答說“我不知，我想我也許希望在太空中做一些慈善的工作，因為我不認為我能夠在太空中做任何商業化的事情，因為那似乎是國家的權限”因此。呃，但你知道，我有點好奇我們何時會送人到火星，然後當我發現那不是在網站上的時候，我開始挖掘，NASA網站上什麼都沒有，然後就開始挖掘。

### Elon Musk <small>[14:09]</small>
嗯，而特斯拉的情況則是與此同時發生的。呃，2008年是艱難的一年。呃，因為在2008年中期，或稱夏季2008年，SpaceX的第三次發射失敗了，這是我們連續的第三次失敗。呃，特斯拉的融資回合也失敗了。因此，特斯拉的破產趨勢迅速加劇。呃，這就像，“天啊，這是多麼可怕的情況。”呃，這將成為一次警示的故事，對某種驕傲的反思。在那段期間，很多人都說，你知道，埃隆是一位軟體人，他為什麼要從事硬體工作？為什麼？是的，為什麼他選擇這麼做？對，100%。所以，您可以查看一下，即便因為那段時間的報導仍然在線，你只需搜索，結果會有很多人繼續稱呼我“網路人”。所以，像網路人，等於愚蠢，正在嘗試建立一家火箭公司。因此，你知道，我們遭受了大量的嘲笑，這聽起來很荒謬，像是網路人開始的火箭公司，聽起來明顯不可能獲得成功的方程。所以我不會責怪他們，我的意思是，是的，坦白說，這聽起來確實不太可能，我同意這一點。但是，幸運的是，第四次發射成功了。呃，NASA授予我們一項合同，以補給太空站。而且我想那可能是在，呃，我想是12月22日，或是在聖誕節前的時候。因為即便第四次發射成功，也不足以獲得成功，NASA也需要一個大型的合同來維持我們的生存。因此，呃，我接到了來自NASA團隊的電話，我真的像是很興奮地脫口而出：“我愛你們。”這通常不是他們聽到的話。因為一般是比較，呃，冷靜的，不過我像是“媽呀，這是公司得救的機會。”然後，呃，我們在最後一小時，最後一天成功完成了特斯拉的融資回合，於是時間是2008年12月24日下午6點，如果那輪融資沒有成功，我們將在聖誕節後兩天就會支付不出工資。因此，那是令人緊張的2008年尾聲，肯定如此。我想，從你在PayPal和Zip 2的經驗中，進入這些相對硬派的硬體初創公司，似乎其中一個主線是能夠找到並最終吸引那些可能在特定領域裡最優秀的人。你知道，這些房間裡的人，一些人我想，他們甚至還沒有管理過人。他們只是剛剛開始自己的職業生涯。對於那些這些人，你會對他們說些什麼，呃，我通常覺得要儘量做到最有用。這聽起來可能有些老套，但要對許多人的幫助來說，真的非常艱難。呃，當時例如整個曲線的面積就是你總共對限法人的用處乘以你幫助了多少人。這幾乎像是物理學定義的真實工作，這是相當難做到的。我認為如果你渴望做真實的工作，呃，你獲得成功的機會將大大提高。呃，像不應該追求榮耀，應該追求工作。你怎麼判斷這是真實的工作呢？像是外部的嗎？還是其他人在做什麼或我產品能為人們做什麼？你知道，這對你來說的意義是什麼？當你在尋找來為你工作的人時，像你，知道的，當他們在你這裡的時候，那些突出的特質是什麼，或者，如果他們，這是另一個問題。我想，我的產品方面，你必須要問：“如果這件事是成功的，那麼它對多少人有用？”那就是我想的，然後你無論是CEO還是任何人在初創公司中，為了成功，你都要做任何事：讓自己持有很低的自我意識且負責。像一個事故的主要成因是自我能力比例或自我主義過高，如果你的自我與能力的比例過高，那麼你會破壞現實的反饋循環，而在AI術語中，你會破壞強化學習循環。因此，你希望不破壞，你的RL循環要有良好的迴圈，這意味著內化責任，減少自我。不論這是好任務還是卑微任務，隨便什麼都可以做到。所以，我是說，這就是為什麼我實際上更喜歡稱呼為“工程”而不是“研究”。我更喜歡這個術語。呃，以及我其實不希望稱XAI為實驗室，我希望它成為一家公司。呃，像這個最簡單的，最直接的，理想上，都是低自我的那些，通常是一個良好的途徑。呃，你只要把對現實的強烈反饋循環閉合。呃，這是非常重要的一步。我認為在這個房間裡的每個人都非常仰望你所做的一切，成為某種原則的典範，然後你知道思考你所做的事情的過程，你是如何確定你的現實的，因為這似乎是其中一個相當大的部分。像其它人。

### Elon Musk <small>[17:00]</small>
這似乎是其中一個相當大的部分。像其它人，會批評你，包括那些從未做過任何事情的非工程師，像是有時候記者他們從未做過任何事情，但他們會批評你，但顯然你有另一批建設者，他們有著非常高的，嗯，我想說是高的對於區域的支持。你知道人們們如何進行這一次，像是，如何面對這種情況，你知道，發生什麼事情？在接下來的五到十年，房間裡的人應該做些什麼，以確保自己成為創造者，而不是低於API線的那一方？他們稱這為奇點有原因，因為我們不知道在不久的未來會發生什麼。人類的智慧比例將會非常小。在某一個時刻，整個人類智慧的總和將會少於所有智慧的1%。無論如何，你知道，即使假設人類人口和智慧有顯著增長，像是大規模的智慧增強，每個人的智慧都是千分之百的情況下， 在這種情況下，外部人類智慧仍然可能是數十億分之一，與數位智慧相比。無論如何，生物學的啟動者是數位超智慧的那部分，我想，結尾的時候，那我像是我算好的啟動者。我們該去往何處？我們該如何前進？我的意思是，所有這些都是相當奇特的科幻故事，也可能由這些房間裡的人建立。你知道，如果你有一種結論的想法對於這一代最聰明的技術人員，現在他們應該做些什麼？應該思考什麼，你知道，今晚他們去吃晚餐時。

### Elon Musk <small>[19:51]</small>
他們應該思考什麼，你知道，今晚他們去吃晚餐時。好吧，如我一開始所說的，我認為如果你在做一些有用的事情，那真是太好了。嗯，試圖對你的同胞人類盡可能地有用，這樣你就是在做好事。因此，我一直強調要專注於超真實的AI，這是人工智慧安全的最重要的一點。呃，顯然，若是有人對於在XAI工作感興趣，我是說，請讓我們知道，我們的目標是使勻整潔的AI成為尋求真相的AI。呃，我認為這是非常重要的事情。我希望我們能理解宇宙的本質。那就是，這個真的，我想AI可以告訴我們的。或許AI能告訴我們外星人在哪裡，呃，還有，宇宙到底是如何開始的？它將如何結束？有什麼我們不知道但應該詢問的問題？還有，我們在模擬中還是我們所處的模擬是哪一層次的？好吧，我想我們會搞清楚。呃，人工智慧發展有一種過程。埃隆，謝謝你這麼多參加。大家，請為埃隆·馬斯克的到來鼓掌。

### Elon Musk <small>[22:40]</small>
it's it's so hard to be useful, especially to be useful to a lot of people. Uh where say the area under the curve of total utility is like how much how useful have you been to your fellow human beings times how many people? Um it like it's almost like like the physics definition of true work. It's incredibly difficult to do that. And I think if you aspire to do true work um your your your probability of success is much higher. Um like like don't aspire to glory aspire to work. How can you tell that it's true work? Like is it external? Is it like what happens with other people or you know what the product does for people like what you know what is that for you when you're looking for people to come work for you? Like what you know what's the salient thing that you look for or if they're you know that's a different question. I guess it's I mean in terms of of of your end product you just have to say like well if this thing is successful how useful will it be to how many people and um that that's that's what I mean and and then you you do whatever you know whether you're CEO or or any role in a startup you do whatever it takes to succeed like and and just and just always be smash smashing your ego like like internalize responsibility um like a major failure mode is when ego ability ratio um is double greater than sign one you know uh like if you if your ego to ability ratio is gets too high then you're you're you're going to basically break the feedback loop to reality u and in in AI terms your your you'll break your RL loop so you you want you don't want to break your you want to have a strong RL loop which means internalizing responsibility and minimizing ego and you do whatever the task is no matter whether it's you grand or humble. So, I mean, that's kind of like why I actually I prefer the term like engineering as opposed to research. I prefer the term and and I I don't I actually don't want to call XAI a lab. I just want to be a company. um like it's like whatever the whatever the simplest um most straightforward uh ideally lowest ego terms are those are generally a good way to go. Um to you you want to just close the loop on reality hard. Um that's that's a that's a super big deal. I think everyone in this room is uh really looks up to everything you've done around being sort of a paragon of first principles and you know thinking about the stuff you've done um how do you actually determine your reality because that seems like a pretty big part of it like other people

### Elon Musk <small>[25:20]</small>
pretty big part of it like other people people who have never made anything non-engineers uh sometimes journalists at time who've never done anything like they will criticize you but then clearly you have another set of people who are builders who have very high you know sort of area under the curve who are in your circle like you know how should people approach that like what has worked for you and what would you pass on like you know to to X to your children like you know what do you tell them when you're like you need to make your way in this world here you know here's how to construct a reality that is predictive from first principles well the the tools of physics are incredibly helpful uh to to um understand and make progress in any field. Um the first principles mean just obviously just means you know break things down to the fundamental aimatic elements that are most likely to be true and then reason up from there as cogently as possible as opposed to reasoning by analysis or metaphor. Um and then you just simple things like like thinking in the limit like if you extrapolate you know minimize this thing or maximize that thing thinking in the limit is is very very helpful. Um I use all the tools of physics. Um they apply to any field. Um this is like a superpower actually. Um so you can take say take take for example like rockets. You can say well how how much should a rocket rocket cost? Um the typical approach to how to that people would take to how much rocket should cost is they would look historically at what the cost of rockets are and assume that any new rocket must be somewhat similar to the prior cost of rockets. A first principles approach would be you you look at the materials that the rocket is comprised of. So if that's aluminum, uh copper, carbon fiber, uh steel, whatever the case may be, um and say what what how much does that rocket weigh and and and what are the constituent elements and how much do they weigh? What is the material price per kilogram of those constituent elements? And that sets the actual floor on what a rocket uh can cost. It's it can asmtoically approach the cost of the raw materials. Um and then you realize oh actually a rocket the raw materials of a rocket are only maybe one or 2% of of the historical cost of a rocket. So the manufacturing must necessarily be very inefficient um if the if the raw material cost is only 1 or 2%. That would be a first first principles analysis of the potential for the cost for cost optimization of a rocket. And

### Elon Musk <small>[27:56]</small>
for cost optimization of a rocket. And that's before you get to reusability. You know to give an AI sort of AI example I guess uh last year where for XEI when we were trying to build a a training supercluster uh we we we went to the various suppliers to ask said this was beginning of last year that we needed 100,000 H100s to be able to train coherently. Um and uh their estimates for how long it would take to complete that were 18 to 24 months. It's like well we need to get that done in 6 months. So then um or we won't be competitive. So so then uh if you break that down what well what are the things you need? Well, you need a building, you need power, you need cooling. Um we didn't have enough time to build a building from scratch. So we had to find an existing building. So, we found a a factory that was no longer in use in Memphis that used to build Electrolux products. Um, but then the the input power was 15 megawatts and we needed 150 megawatt. So, uh we we um rented generators and had generators on one side of the building and then we have to have cooling. So, we rented about a quarter of the mobile cooling capacity of the US and put the the chillers on the other side of the building. uh that didn't fully solve the problem because the voltage v the power variations during training um are are very g very big. So you can have power can drop by 50% in 100 milliseconds which the generators can't keep up with. So then we combi we added Tesla mega packs and modified the software in the mega packs to be able to to smooth out the uh the power variation during the training run. Um, and then there were there were a bunch of network networking challenges. Um, because the networking cables if you're trying to make 100,000 GPUs train coherently are very very challenging. Um, almost it sounds like uh almost any of those things you mentioned uh I could imagine someone telling you very directly, no, you can't have that, you can't have that power, you can't have this. Uh, and it sounds like one of the salient pieces of first principles thinking is actually let's ask why. let's, you know, figure that out and actually let's challenge the person across the table and if they if I don't get an answer that I feel good about, I'm gonna, you know, not allow that to be I'm not going to let that know to stand. Is that I mean, that feels like something that, you know, everyone, if someone were to try to do what you're doing in hardware, hardware seems to uniquely need this. In software, we have lots of, you know,

### Elon Musk <small>[30:30]</small>
software, we have lots of, you know, fluff and things that, you know, it's like we can add more CPUs to that. it'll be fine. But in hardware, it's it's just not going to work. I think these general principles of first principle thinking apply to software and hardware apply to anything really. Um I'm just using kind of a hardware example um of of how we were told something is impossible, but once we broke it down into the constituent elements of we need a building, we need power, we need cooling, we need uh we we need power smoothing and then and then we could solve those constituent elements. Um but it it was and then we and then we just ran the the networking operation to to do all the cabling everything um in four shifts 247 and and I was like sleeping in the data center and also doing cabling myself. Um and and there were a lot of other issues to solve. Um you know nobody had done a training run with 100,000 um H100s training coherently last year. May maybe it's been done this year. I don't know. Um and then and then we ended up doubling that uh to 200,000. And so now we we've got 150,000 H100s, 50K H200s, and 30K GB200s um in the in the Memphis uh training center. And we're about to bring 110,000 GB200s online um at a second data center also in the Memphis area. Is it your view that you know uh pre-training is still working and you know larger the scaling laws still hold and whoever wins this race will have basically the biggest smartest possible model that you could distill? Well, there's other various elements that um beside competitiveness for for large AI um there's there's for sure the the talent of the people matter. Um the scale of the hardware matters and how well you able to bring that hardware to bear. So you can't just order a whole bunch of GPUs and they they don't you can't just plug them in. So you've got to you've got to get a lot of GPUs and have them um train trained coherently and stably. Um then it's like what unique access to data do you have? I guess distribution matters to some degree as well like how do people get exposed to your AI? Those are those are critical factors for if it's going to be like a large foundation model that's competitive. Um um you know as um as many have said I think my friend I sky said uh you know we've kind of run out of pre-training data of human generated pre like human generated data you run out of tokens pretty fast um of certainly of high quality tokens and um and then you and you have to do a lot of uh you you need to essentially

### Elon Musk <small>[33:23]</small>
a lot of uh you you need to essentially create synthetic data um and and be able to accurately judge the synthetic data that you're creating to verify like is this real synthetic data or is it an hallucination that doesn't actually match reality. Um so achieving grounding in reality is is is tricky but but we we are at the stage where there's more effort put into synthetic data. Um and like right now we're we're training Grock 3.5 which is a a heavy focus on reasoning. Going back to your physics point, uh what I heard for reasoning is that uh hard science particularly physics textbooks are very useful for reasoning whereas um I think researchers have told me that social science is totally useless for reasoning. Uh yes, that's probably true. Um so yeah um you know something that's going to be very important in the future is um combining deep AI uh in the the data center or supercluster with robotics. Uh so that uh you know things like like the Optimus humanoid robot and um yeah Optimus is awesome. There's going to be so many humanoid robots and and robots of all robots of all sizes and shapes, but my prediction is that there will be more humanoid robots by far than all other robots combined by maybe an order of magnitude like a a big difference. Um and um is it true that you you're planning a robot army of a sort? Whether we do it or or or you know whether Tesla does it, you know, Tesla works closely with XAI. Um, like you've seen how many humanoid robot startups are there. Like it's like I think Jensen Bong was on stage with a lot with a massive number of robots, you know, robots from different companies. I think there was like dozen different humanoid robots. So, I mean, I guess, you know, part of what I've been fighting and maybe what has slowed me down somewhat is that I'm a I'm a little I don't want I don't want to make Terminator real, you know. So, I've been sort of I guess at least until recent years dragging my feet on on AI and and humanoid robotics. And then I sort of come to the realiz realization it's it's happening whether I do it or not. So, you got really two choices. Particip you could either be a spectator or a participant. And so, like, well, I guess I'd rather be a participant than a spectator. Um so now it's you know pedal to the metal on humanoid robots and um digital super intelligence. So I guess you know there's a third thing that uh everyone has heard you talk a lot about that I'm really a big fan of you know becoming a multilanetary species. Where

### Elon Musk <small>[36:18]</small>
becoming a multilanetary species. Where does this fit? You know this is all you know not not just a 10 or 20 year thing maybe a hundredyear thing like it's a mult you know many many generations for humanity kind of thing. You know how do you think about it? There's, you know, AI, obviously, there's embodied robotics, and then there's being a multip multilanetary species. Does everything sort of feed into that last point or, you know, what what are you driven by right now for the next 10, 20, and 100 years? Jeez, 100 years, man. I hope civilization's around in 100 years. If if it is around, it's going to look very different from civilization today. Um, I mean, I'd predict that there's going to be at least five times as many humanoid robots as there are humans, maybe 10 times. Um, and one way to look at the progress of civilization is percentage completion kadesv. So, if you're, you know, cautious of scale one, you've um, you've harnessed all the energy of a planet. Now in in my opinion we've only uh harnessed maybe 1 or 2% of uh earth's energy. Uh so we've got a long way to go to the cev scale one. Uh then car shift 2 you've harnessed all the energy of a sun. Uh which would be I don't know a billion times more energy than earth maybe closer to a trillion. Um and then kv 3 would be all the energy of a galaxy pretty far from that. So we're at the very very early stage of the intelligence big bang. I I I hope I hope we're on the in terms of being multilanetary like I think I think we'll have enough mass transferred to Mars within like roughly 30 years to make Mars self- sustaining such that Mars can continue to grow and prosper even if the resupply ships from Earth stop coming. Um and that that greatly increases the probable lifespan of civilization or or consciousness or intelligence both biological and digital. Um so that's why I think it's important to become a multilanet species. And I'm somewhat troubled by the foamy paradox like why have we not seen any aliens? And it could be because intelligence is incredibly rare. Um and maybe we're the only ones in this galaxy. Um in which case the intelligence of consciousness is this like tiny candle in a vast darkness and we should do everything possible to ensure the tiny candle candle does not go out and being a multilanet species or making consciousness multilanetary uh greatly improves the probable lifespan of civilization and it's it's it's the next step before going to other star systems. Um once you once you at

### Elon Musk <small>[39:11]</small>
star systems. Um once you once you at least have two planets, then you've got a forcing function for the improvement of space travel. Um and um and that that ultimately is what will lead to uh consciousness expanding to the stars. It could be that um the Fermy paradox dictates once you get to some level of technology, you destroy yourself. How do we say ourselves? How do we actually what would you prescribe to I mean a room full of engineers like what can we do to prevent that from happening? Yeah. How do we avoid the great filters? One of the great filters would obviously be global thermonuclear war. Uh so we should try to avoid that. Um, I guess building benign AI robots that AI that loves humanity and um, you know, robots that are helpful. Um, something that I think is uh, extremely important in building AI is is a very rigorous adherence to truth even if that truth is politically incorrect. Um I my intuition for what could make AI very dangerous is if um if you force AI to believe things that are not true. How do you think about you know there's sort of this argument for open uh open for safety versus closed for competitive edge. I mean I think the great thing is you have a competitive model. Many other people also have competitive models. And in that sense, you know, we're sort of off of maybe the worst timeline that I'd be worried about is, you know, there's fast takeoff and it's only in one person's hands. You know, that might, you know, sort of collapse uh a lot of things. Whereas now we have choice, which is great. How do you think about this? Yeah, I do think there will be several deep intelligences, may maybe at least five. Um maybe as much as 10. Um, I'm not sure that there's going to be hundreds, but it's probably close to like maybe there'll be like 10 or something like that. Um, of which maybe four will be in the US. Um, so I I don't think it's going to be any one AI that that has a runaway capability. Um but but yeah se several deep intelligences. What will these deep deep intelligences actually be doing? Will it be scientific research or trying to hack each other? Probably all of the above. Um I mean hopefully they will discover new physics and I think they will very they're they're definitely going to invent new technologies. Um like I think I think we're quite close to digital super intelligence. It may happen this year and if it doesn't happen this year, next year for sure a digital super intelligence defined as smarter than any human at

### Elon Musk <small>[42:18]</small>
defined as smarter than any human at anything. Well, so how do we direct that to sort of super abundance? You know, we have we could have robotic labor, we have cheap energy, intelligence on demand. you know, is that sort of the white pill? Like where do you sit on the spectrum? And are there tangible things that you would encourage everyone here to be working on to make that white pill actually reality? I think I think it most likely will be a good outcome. Um I I guess I'd sort of agree with Jeff Hinton that maybe it's a 10 to 20% chance of annihilation. Uh but look on the bright side, that's 80 to 90% probability of a great outcome. Um, so yeah, I can't emphasize this enough. A rigorous adherence to truth uh is is the most important thing for AI safet safety. Um, and obviously empathy for uh humanity and life as we know it. We haven't uh talked about Neurolink and uh at all yet, but I'm curious, you know, you're working on closing the input and output gap between humans and machines. Uh how critical is that to AGI ASI? And you know, once that link is made, can we not only read but also write the neural link is not necessary to solve um digital super intelligence. Uh that'll happen before neural link is at scale. Uh but uh what Nurolink can effectively do is solve the um the input output bandwidth constraints. Especially our output con bandwidth is very low. The the out the the sustained output of a human over the course of a day is less than one bit per second. So there, you know, 86,400 seconds in a day. Um and is extremely rare for a human to output more than that number of symbols per day. So um certainly for several days in a row. Uh so you you really um with with a with a neural link interface you can massively increase your output bandwidth and your input bandwidth. Um input being right to you you have to do write operations to the brain. Um we um we have now five humans who have received the uh the kind of the read uh input where it's reading signals. And you've got people with with ALS who um really have no they're tetroplegics, but they they can now communicate at with with at um similar bandwidth to a human with a fully functioning body um and control their computer and phone um which is pretty cool. And then um I think in the next 6 to 12 months we'll be doing our first implants for vision where even if somebody's completely blind um uh we we can write directly to um the uh the visual cortex um and and we've had that working in monkeys actually. I think one

### Elon Musk <small>[45:22]</small>
working in monkeys actually. I think one of our monkeys now has had a visual implant for three years and um at first it'll be relatively fairly low resolution but long term you would have very high resolution and be able to see multisspectral wavelengths. So uh you could see an infrared ultraviolet radar like a superpower situation like at at at some point the cybernetic implants wouldn't would not simply be correcting things that went wrong but uh augmenting human capabilities dramatically augmenting augmenting intelligence and senses and bandwidth uh dramatically and that's that's going to happen at some point. Um but digital super intelligence will happen well before that at least if we have a a neural link we might we'll be able to appreciate the the AI better I guess one of the limiting reagents to all of your efforts across all of these different domains is access to the smartest possible people. Um, yes. But, you know, sort of simultaneous to that we have, you know, the rocks can talk and reason and, you know, they're maybe 130 IQ now and they're probably going to be super intelligent soon. Uh, how do you reconcile those two things? Like what's going to happen in you know 5 10 years and what should the people in this room do to uh make sure that, you know, they're the ones who are creating instead of maybe below the API line? Well, they call it the singularity for a reason because we don't know what's going to happen in in the not that far future. The percentage of intelligence that is human will be quite small. At some point, the collective sum of human intelligence will be less than 1% of all intelligence. Um and if if things get to a cauter ship level two um we're talking about human intelligence even assuming a significant increase in human population and intelligence augmentation like massive intelligence augmentation where like everyone has an IQ of a thousand type of thing. Um even in that circumstance uh collective human intelligence will be probably 1 billionth that of uh digital intelligence. Anyway, where's the biological bootloader for digital super intelligence? I guess just to end off was I he was like was I a good bootloader. Where do we go? How do we go from here? I mean I mean all of this is pretty wild sci-fi stuff that also could be built by the people in this room. You know, if you do you have a closing thought for the smartest technical people of this generation right now, what should they be doing? What should they what should they be working on?

### Elon Musk <small>[48:13]</small>
they what should they be working on? What should they be thinking about, you know, tonight as they go to dinner? Well, I as I started off with, I think if you're doing something useful, that's great. Um, if you just just try to be as useful as possible to your fellow human beings and that that then you're doing something good. Um, I keep harping on this like focus on super truthful AI that that's the most important thing for AI safety. Um, you know, obviously if you know um anyone's interested in working at XAI, I mean, please please let us know. Um we're aiming to make gro um the maximally truth seeeking AI. Um and uh I think that's a very important thing. Um hopefully we can understand the nature of the universe. That that's really I guess what AI can hopefully tell us. Maybe AI AI can maybe tell us where are the aliens and what you know how did the universe really start? How will it end? What are the questions that we don't know that we should ask? And um are we in a simulation or what level of simulation are we in? Well, I think we're going to find out. An NPC. Elon, thank you so much for joining us. Everyone, please give it up for Elon Musk.
