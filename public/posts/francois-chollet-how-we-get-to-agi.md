<!-- summary -->
總結：Francois分享了有關人工智能（AI）以及通用人工智能（AGI）的見解，重點闡述了計算能力的降低、AI的發展歷程，以及未來朝AGI的演進方向。特別是，他強調了適應能力在智慧中的重要性，並對傳統的評估方式提出了質疑。

重點：
1. 自1940年以來，計算成本穩定下降，推動了AI技術的進步，特別是深度學習的發展。
2. 擴大模型訓練的過程並未使我們達成AGI，因為現有基準測試只能測量靜態技能，未能真正反映流動智能。
3. 流動智能的核心是即時理解和處理未見過的新問題的能力，而不是依賴記憶和靜態知識。
4. 近年來，AI社群開始轉向「測試適應」的方法，使模型能夠在推理過程中動態調整，以適應新情況，顯示出更接近流動智能的進展。
5. 為實現AGI，我們需要重新定義智能的測量標準，強調創新和應對新挑戰的能力，超越單純的自動化。
<!-- endsummary -->

<small>原始影片：[https://www.youtube.com/watch?v=5QcCeSsNRks](https://www.youtube.com/watch?v=5QcCeSsNRks)</small>

### François Chollet <small>[00:03]</small>
大家好，我是Francois。我非常興奮能與大家分享一些我對HGI的想法，以及我們要如何實現它。這裡的圖表顯示了關於世界的最重要事實之一。自1940年以來，計算成本每十年一直穩定下降兩個數量級，並且沒有任何跡象顯示這種趨勢將會停止。在人工智慧領域，計算和數據長期以來一直是我們所能達成的主要瓶頸。在2010年代，大家都知道，隨著基於GPU的計算和大型數據集的出現，深度學習真的開始見效。突然之間，我們在計算機視覺和自然語言處理等問題上取得了快速進展，這些問題在過去長期以來似乎克難無法解決。特別是，自我監督的文本建模開始發揮作用。AI的主導範式變成了擴大LM3的訓練，而這種方法幾乎壓倒了所有基準，並且值得注意的是，在模型規模和訓練數據規模隨著完全相同的架構和訓練過程擴大時，它的基準結果變得可預測地變得更好。這就是Jared幾分鐘前告訴你的擴展法則。因此，似乎所有的事情都被搞定了，許多人推測更大的規模是解決一切、達成AGI所需的唯一因素。我們的領域對於一般智能將會自然而然地出現的這一觀點變得著迷，只需將更多數據塞進越來越大的模型中。然而，問題來了。我們對這些基準的真正含義感到困惑。記憶技能是靜態且特定任務的，而流動的一般智能則是即時理解從未見過的事物的能力。回到2019年，在LLMs崛起之前，我發布了一個AI基準來突出這種差異。它稱為抽象推理語料庫（ARK1）。從2019年到現在，以像GP4.5這樣的模型為例，基準的擴大約為50000倍，而我們在該基準上的準確率從0%提高到約10%。這還不是很多。如果考慮到你們中的任何一位在座的人的得分會遠超95%，那麼這個數字就非常接近於零。因此，要解開一般流動智能，結果我們需要的不僅是擴大預訓練和靜態推理的新想法。這個基準並不是關於重複記憶技能的，而是關於理解從未見過的新問題。

### François Chollet <small>[02:54]</small>
這個問題是你從未見過的新問題。但是，去年2024年，一切都發生了變化。AI研究社區開始轉向一種全新且非常不同的模式——測試適應，創建能在測試時改變自身狀態以適應新事物的模型。因此，這不再是查詢預先裝載的知識，而是真正關乎在推理時學習和適應的能力，突然間我們開始在ARC上看到顯著進展。因此，我們終於有了顯示出真實流動智能跡象的AI。特別是在去年12月，OpenAI預覽了他們的03模型，他們使用的一個版本是專門在ARC上進行微調的，並首次在該基準上顯示出人類級別的表現。而今天，2025年，我們突然從預訓練擴大的模式中轉變，現在完全進入了Tesla適應時代。Tesla適應的重點在於模型基於推理過程中遇到的特定數據動態修改其行為的能力。因此這涵蓋了像測試時訓練、程序合成、思維過程合成這樣的技術，其中模型試圖重新編程自己以適應當前的任務。今天，所有在ARC上表現良好的AI方法都在使用其中的一種技術。因此，今天我想回答以下問題。首先，為什麼預訓練擴大範式沒有使我們達到AGI？如果你回顧兩年前，這是標準教條。每個人都這麼說，而今天幾乎沒有人再相信這一點。那麼，發生了什麼事？接下來，這種適應這次能讓我們達到AGI嗎？如果是這樣，也許AGI已經在這裡。有些人這樣認為。最後，除了這種適應之外，AI的未來還可能有什麼？要回答這些問題，我們必須回到一個更根本的問題上來。什麼才是智能？當我們說我們在努力建設AGI時，我們到底是什麼意思？如果你回顧過去幾十年，人們對智能的定義和AI的目標有兩種思路。一種是Minsky風格的觀點。AI是為了創造能執行本來會由人類完成的任務的機器。這非常接近當前主流公司的觀點，即AGI將是一個能執行大多數經濟上有價值的任務的模型，通常會引用80%的數字。另一方面，則是另一種看法，AI的目的是讓機器處理它們未經準備的問題。它是讓AI能夠處理新事物。因此，我的觀點更接近MATI的觀點。智能是一個過程，而技能則是該過程的輸出。

### François Chollet <small>[05:43]</small>
技能本身並不是智能，在許多任務上展現技能並不顯示出智能。這就像是道路網絡與道路建設公司之間的區別。如果你擁有一個道路網絡，那麼你可以在特定的預定A點和B點之間通行。但是如果你擁有一個道路建設公司，那麼你可以根據需求的演變，開始連接新的A點、新的B點。智能是處理新情況的能力，開辟新道路並建造新道路的能力。因此，將智能歸因於僵化的行為程序，即技能程序，這是一種類別錯誤。你在混淆過程和其輸出。所以不要混淆道路和創造道路的過程。為了更正式地表達一下，我將智能視為你擁有的信息與你在潛在未來情況空間中的操作範疇之間的轉換比率，這將特徵出高度的新奇性和不確定性。因此，智能就是你高效地運用過去的信息以應對未來的能力。這是一個效率比率，這也是為什麼使用考試類似基準模型是一個糟糕主意的原因。它們不會告訴你我們距離AGI有多近，因為人類考試並不是為了測量智能而設計的。它們是為了測量特定任務的技能和知識而設計的。它們是根據對人類來說合情合理的假設設計的，但對機器則不然。例如，大多數考試都假設你在考試之前沒有閱讀並記住所有問題和答案。因此，如果你想明確定義和測量智能，這裡有一些關鍵概念需要考慮。首先是靜態技能與流動智能之間的區別。這是擁有解決已知問題的靜態程序集合的能力，與能夠即時生成全新程序以面對從未見過的新問題的能力之間的區別。當然，這並不是二元的，它們之間存在著一個光譜。第二個概念是對於給定技能的操作範圍。僅在非常接近你之前見過的情況下擁有技能與能夠在非常廣泛的範疇中應對任何情況之間存在著巨大的區別。例如，如果你會駕駛，你應該能夠在任何城市駕駛，而不僅僅是在特定的地理圍欄內。就像你可以在聖荷西學會駕駛，然後搬到薩克拉門托，仍然能夠駕駛一樣。再次強調，這裡仍然有一個光譜，並不是二元的。最後，你應該考慮對於特定技能的信息效率。為了獲得該技能，你需要多少信息、多少數據、多少練習？當然，較高的信息效率意味著較高的智能。

### François Chollet <small>[08:29]</small>
事實上這些定義之所以重要，因為作為工程師，我們只能構建我們所測量的東西。因此，我們定義和測量智能的方式不是技術細節，它真正反映了我們對認知問題的理解。它為我們將要提出的問題設置了範疇，因此決定了我們將獲得的答案。這是驅動我們朝向目標前進的反饋信號。在工程中不斷出現的一種現象是捷徑法則。這意味著當你專注於實現單一的成功度量時，雖然你可能會成功，但卻會以犧牲所有其他未能被你的度量捕獲的東西為代價。因此，你命中目標卻錯過了要點，你在Kaggle上經常會看到這一點。我們在Netflix獎中看到了這一點，當時獲獎系統的準確度很高，但它太過複雜，根本無法用於生產環境，因此最終未能被使用，實際上是無意義的。我們也在AI中看到了這一點，尤其是撲克AI。在70年代，AI社區試圖創造能夠下棋的程序，因為人們預計這將有助於我們了解人類智能。幾十年後，當Deep Blue擊敗世界棋王Kasparov時，我們達成了目標，但在這個過程中我們並沒有真正學到什麼關於智能的知識。因此，你命中目標卻錯過了要點。幾十年來，AI一直追逐特定任務的技能，因為這是我們對智能的定義。但是，這個定義只能導致自動化，這正是我們在今天擁有的系統。我們其實希望AI能夠進行自主創新。我們不想停留在自動化已知任務的層面上。我們渴望能夠解決人類最困難挑戰的AI，並加速科學進步。這就是AGI的目的。為了實現這一點，我們需要一個新的目標。我們需要停止以流動智能本身為目標，即適應和創新的能力。一種對AGI的定義僅僅包含了自動化。這會提高經濟生產力。顯然，這是極具價值的，但它也可能導致失業。另一个定义则解锁了创造力和科学进展的加速。只有通过衡量你真正关心的事物，我们才能够取得进展。因此，我们需要更好的目标，需要更好的反馈信号，这样看起来将是怎么样呢？我第一次尝试创造一种测量AI系统智能的方法是RKGI基准。我在2019年发布ARK1，它就像是机器和人类的智商测试。ARK1包含1000个任务，像这个任务一样。每个任务都是独特的，这意味着你不能为ARC准备。你必须通过使用你的通用智能即兴解决每个任务，而不是依靠记忆知识。當然，解決任何問題始終需要某種知識。至於大多數基準所需要的知識先前，通常都是隱性地存在的。在ARK的案例中，我們使它們明確化，因此所有ARC任務都是完全基於核心知識的前提而構建的，這些知識的內容例如對象性、基本物理學、基本幾何學、拓撲和計數等。因此，解決ARK幾乎不需要專業知識，而且這些知識非常不具特殊性。因此，您不需要為了解決ARK而進行準備。而使ARK獨特的是，您無法僅通過記憶模式來解決它。它真的是需要您通過智能來證明。

### François Chollet <small>[11:07]</small>
AI that could tackle humanity's most difficult challenges and accelerate scientific progress. That's what AGI is meant to be. And to achieve that, we need a new target. We need to stop targeting fluid intelligence itself, the ability to adapt and invent. So one definition of AGI only enops automation. So it increases economic productivity. Obviously, it's extremely valuable. Maybe it also increases unemployment. But the other definition unlocks invention and the acceleration of the timeline of science. And it's by measuring what you really care about that we'll be able to make progress. So we need a better target. We need a better feedback signal. What does that look like? My first attempt at creating a way to measure intelligence in AI systems was the RKGI benchmark. So I released ARK1 back in uh 2019. It's like an IQ test for machines and also humans. So ARK1 contains 1,000 tasks like this one here. And each task is unique. So that means that you cannot cram for ARC. You have to figure out each task on the fly by using your general intelligence rather than your memorized knowledge. And of course solving any problem always requires some knowledge. And in the case of most benchmarks, the knowledge prior that you need are typically left implicit. In the case of ARC, we made them explicit. So all ARC tasks are built entirely on top of core knowledge prior which are things like objectness, uh elementary physics, um basic geometry, topology, counting. So concepts that any fouryear-old child has already mastered. And solving arc requires very little knowledge and it's knowledge that is very much not specialized. So you don't need to prepare for arc in order to solve it. And what makes arc unique is that you cannot solve it purely by memorizing patterns. It really requires you to demonstrate through the intelligence. And meanwhile pretty pretty much every other benchmark out there is targeting fixed known tasks. So they can't actually be solved or hacked via memorization alone. That's what makes ARC fairly easy for humans but very challenging for AI. And when you see a problem like this where a human child can perform really well but the most advanced the most sophisticated AI models out there struggle that's like a big red flashing light telling you that we're missing something that new ideas are needed. One thing I want you to keep in mind is that ARC is not going to tell you whether a system is already a GR or not. That's not its purpose. Arc is really a tool to direct the attention of

### François Chollet <small>[13:51]</small>
與此同時，幾乎所有其他基準都旨在針對已知的固定任務。因此，它們無法僅依靠記憶來解決或黑客攻击。這就是為什麼ARC對於人類來說相對容易，但對於AI卻非常具有挑戰性的原因。當你看到一個問題時，像這樣一個人類的孩子能表現得非常好，但最先進的AI模型卻在艱難應對時，這就像一個閃爍的紅燈，告訴你我們遺漏了什麼，需要新想法。我要提醒你的是，ARC無法告訴你一個系統是否已經達到G或不達到。這並不是它的目的。ARC確實是一種工具，旨在引導研究社區關注我們認為在通往AGI途中最重要的未解決瓶頸。因此，ARC並不是目標，解決ARC並不是目標。ARC只是一個指向正確方向的箭頭，而ARC完全抵制了預訓練擴大範式。即使經過50,000倍的預訓練擴展，它們在ARC的表現仍然幾乎為零。因此，我們可以確定地得出結論：流動智能並不是通過擴大預訓練而出現的。您必須絕對依賴測試適應來真正展示真正的流動智能。而重要的是，當測試適應的出現發生在去年時，ARC當時也是唯一一個對出現的重大變化提供明確信號的基準，其他基準都已飽和，無法區分真正的智力增長與單純的強制擴大。因此，現在你看看這個圖表，你可能會在想，《ARK1》顯然也要飽和了。那麼，這是否意味著我們現在擁有了人類等級的AI？暫時還沒有。你在這個圖表上看到的是，《ARK1》是一項二元測試。它是流動智能的最小重現。因此，它真的只提供兩種可能模式。要麼你沒有流動智能，在這種情況下，你的得分接近於零，就像BASEL一樣，要麼你有非零流動智能，在這種情況下，你會像OpenAI的O3模型那樣瞬間獲得很高的分數。當然，在座的每位都會在距零值的距離內接近100%。因此，ARC飽和了，而ARK1則在非常低的流動智能水平飽和。因此，現在我們需要一種更好的工具，一個更敏感的工具，它能提供更有用的帶寬，並能與人類智力更好地進行比較，而這個工具就是在今年三月發佈的ARKGI 2。在2019年，ARK1旨在挑戰深度學習模式，當時模型是用於靜態推理的巨大參數曲線，而今天的ARK2挑戰推理系統，改變了測試適應範式。基準格式仍然是相同的，對組合標準化的探測焦點大大提高。因此，任務對人類仍然非常可行，但它們變得更為複雜。因此，ARK2並不容易被迫批量處理。在實際中，這意味著在ARK1中，對於許多任務，你可以看到解決方案，而無需過多思考。而對於ARK2，所有任務都需要某種水平的深思，但仍然對人類非常可行。我們知道這是因為我們在聖地牙哥的幾天內親自測試了400人。我們不是在說擁有物理PhD的人。我們招募了隨機的普通人，例如Uber司機、UCDS學生和失業者。換句話說，任何試圖在業餘時間賺錢的人。ARK2的所有任務至少被看見兩次，每個任務在平均上被約七個人看到。因此，這告訴你，一組10位隨機人的多數投票將在ARK2中獲得100%的得分。這告訴我們，這些任務對普通未經專業培訓的人來說是完全可行的。

### François Chollet <small>[16:44]</small>
那麼，AI模型做得怎麼樣呢？如果你以如GPT4.5、Lama 4這樣的基本模型來看，它們的表現很簡單：得分為0%。根本無法僅利用記憶來完成這些任務。接下來，如果你看靜態推理系統，即利用生成的思考鏈的一個單一的思路來處理任務，表現也並不會更好，會在1%-2%的範圍內。這告訴你，為了解決ARK2，您真的需要測試適應。所有表現在0以上的系統都在使用TTL，但即便如此，它們仍然遠低於人類水平。因此，與ARK1相比，ARK2使得對DTS系統的評估變得更加細緻。例如，03模型就是其中一個例子。這就是這樣你會發現，像03和其他類似系統仍然遠未達到人類水平。在我看來，只要我們能輕易找出你們之中任何一個人能勝任的、對人類來說容易的任務，而AI卻無法解決，不論電腦再怎麼努力，我們就無法擁有AGI。你會知道我們距離AGI的邊界愈來愈接近，當出現這樣的任務時仍然會越來越艱難。我們顯然還沒有達到這一點。明確地說，我不認為ARK2是最後的測試。我們不會在ARK2停止。我們在RKGI 3上已經開始開發，ARK3與ARK1和ARK2的輸入輸出對應格式有著顯著的不同。我們正在評估代理性的能力，包括探索、互動性學習、設定目標和自主實現目標的能力。因此，AI將被放置在一個全新的環境中，在那裡它不知道控製和玩法的具體情況，它不知道目標是什麼，甚至不知道遊戲機制，因此只能即興解決一切，首先要弄清楚它應該做什麼。每一款遊戲都是完全獨特的，所有遊戲都建立在核心知識的基礎之上，就像在ARK1和ARK2中一樣。我們將有數百個交互式推理任務，這些任務的設計強調效率，因此模型不僅僅是通過能否解決任務來得分，還會根據它們解決任務的效率來評分。我們還設立了模型可以採取的行動數量的嚴格限度，並以人類觀察到的同一水平的行動效率為目標。我們將在2026年初推出這項技術，而下個月7月，我們將發布開發者預覽版，讓大家可以開始玩。在解決ARK2的這方面，目前距離還很遙遠。至於如何解決ARK3，我們距離那仍然更遙遠。也許未來我們會解決ARK4，最終達成AGI。我們還缺少什麼呢？我曾經說過，智能是以高效地運用過去，以面對不斷變化的未來的能力。然而，當然，如果你所面對的未來與過去完全沒有任何共同之處，無法與任何你已經見過的事物產生聯繫，不論你有多智能，你都無法理解它。可是，事情是，沒有什麼事情是真正新穎的。你周圍的宇宙由許多不同的事物組成，但它們彼此之間都有相似之處。就像一棵樹與另一棵樹所相似，也和你的神經元或電磁學相似，還有流體力學，也和重力相似。因此，我們被同構所包圍。我稱這種現象為萬花筒假設。我們的世界經驗似乎突顯出一種不斷的創新和複雜性，但描述它所需的獨特意義原子實際上非常少，而周圍的一切都是這些原子的重新組合。智能就是挖掘你的經驗，識別這些可以在許多不同情境中重複使用的意義原子，而在很多不同的任務之間這種尋找涉及確定不變性結構，即那些似乎重複的原則。這些構建塊稱為抽象。而每當你遇到新的情況時，你都會通過即時重組你的原子，創造一個全新的適合那個情況的模型。因此，實現智能將有兩個關鍵部分。首先是抽象獲取。你需要能夠高效提取可重用的抽象，無論來自於過去經驗還是從數據流中獲得。第二部分是即時重組。你要能夠高效選擇和重組這些構建塊，以創建適合當前情況的模型。而這裡強調的效率至關重要。你的智能不僅在於你是否能完成某件事，還在於你從過去經驗中多高效獲取良好的抽象以及你能多高效重組它們來應對新穎事物。

### François Chollet <small>[19:34]</small>
what is it even supposed to do uh, uh, in the game. And every single game is entirely unique. They're all built on top of core knowledge prior only, just like in AR one and two. So we'll have hundreds of interactive reasoning tasks like this one. And efficiency is central to the design of AR 3. So models won't just be graded on whether they can solve a task, but on how efficiently they solve it. And we are establishing a strict limit of the number of actions that a model can take. And we are targeting the same level of action efficiency as we observe in human. So we're going to launch this in early 2026 and next month in July we're going to release a developer preview so you can start playing with it. What's it going to take to solve AR 2 and we're still very far from it today. Uh then solve AR 3 and we're even further away from that. Maybe in the future solve AR 4 eventually get to AGI. What are we still missing? So I've said that intelligence is the efficiency with which you operationalize the past to face a constantly changing future. But of course if the future you face had really nothing in common with the past, no common ground with anything you've seen before, you could not make sense of it no matter how intelligent you were. But here's the thing. Nothing is ever truly novel. The universe around you is made of many different things that are all similar to each other. Like one tree is similar to another tree is also similar to your neuron or electromagnetism is similar to hydrodnamics is also similar to gravity. So we are surrounded by isomorphisms. I call this the kaleidoscope hypothesis. Our experience of the world seems to feature a neverending novelty and complexity. But the number of unique atoms of meaning that you need to describe it is actually very small. And everything around you is a recombination of these atoms. And intelligence is the ability to mine your experience to identify these atoms of meaning that can be reused across many different situations, across many different tasks. And this involves identifying um invariance uh structure uh things that seem to be repeated principles. And these building blocks, these atoms are called abstractions. And whenever you encounter a new situation, you're going to make sense of it by recombining on the fly abstractions from your collection to create a brand new model that's adapted to the situation. So implementing intelligence is going to have two key parts. First, there's abstraction acquisition. You want to be

### François Chollet <small>[22:18]</small>
智能不僅僅是展現出高技能，而是以高效率獲得和展現這些技能的能力。這同時涉及數據效率和計算效率。這也是為什麼你會開始了解，僅僅使我們的AI模型變得更大、在更多數據上進行訓練並不會自動導致AGI。我們缺少幾樣東西。首先，這些模型缺乏即時重組的能力。因此，在訓練時，他們學習了很多，獲得了許多有用的抽象，但在測試時，它們完全靜態。你只能使用它們來提取並應用預錄的模板。這是一個關鍵的問題，而測試適應正在解決這個問題。TTA給我們的AI添加了重組能力，而這實際上是讓我們接近AGI的一大進步。但這不是唯一的問題，重組並不是唯一缺失的東西。另一個問題是這些模型的效率依然非常低。如果以梯度下降為例，梯度下降需要大量的數據來提煉簡單的抽象，這比人類需要的數據多幾個數量級，差不多多達三到四個數量級。如果你看看重組效率，即使是最新的尖端TTA技術，它們仍然需要數千美元的計算資源才能在AGI的水準上解決ARK1。而且這甚至無法擴展到ARK2。根本問題在於深度學習模型缺乏組合性泛化。而這正是ARK2試圖測量的東西。原因是，抽象的不止一種，而這一點相當重要。我曾經說過，智能是從數據中挖掘抽象，然後再進行重組，而有兩種抽象形式。第一種類型和第二種類型相似，彼此相互映射。兩者都與比較事物、比較實例並通過消除某些細節將個別實例合併為公共模板有關。因此，基本上你會拿一堆東西，進行比較，丟掉不重要的細節，而你所剩下的便是抽象，而兩者之間的關鍵區別在於一種運行在連續域上，另一種運行在離散域上。因此，第1類或價值型抽象是透過連續距離函數的比較事物，這樣的抽象與感知、模式認知和直覺有關，當然也包括現代機器學習，而第2類或程序型抽象是關於比較離散程序，也就是說圖形，而不是嘗試計算它們之間的距離，而是專注於尋找精確的結構匹配，尋找精確的同形性、子圖同形性。這些正是人類推理的基礎，在軟體工程師重構一些代碼時，所做的就是這些。如果你聽到軟體工程師談論抽象，他們指的是這種抽象。因此，兩種抽象，都是依賴於比喻做推理的。所有的認知都是這兩種形式抽象的結合。你可以想起它們，這是左腦和右腦的比喻。左半邊用於感知、直覺，而右半邊則用於推理、計畫和嚴謹。變壓器在第1類抽象上表現出色，能完成所有第1類抽象能有效應對的任務，即感知、直覺、模式認知等，但在第2類抽象上仍然不合適。因此，這就是為什麼你會發現訓練這些模型來完成非常簡單的第2類任務，例如對一串標記進行排序或相加的話，會非常困難。我們將如何達到第2類呢？你必須利用離散程序搜尋，而不是僅僅操作連續插值空間進行梯度下降。搜尋是解鎖超越自動化的創新的關鍵。如今所有已知的能夠進行某種創造力或創造性的AI系統，都依賴於離散搜尋。甚至在90年代，我們已經使用巨大搜索來提出新的天線設計。或者你可以舉個例子，AlphaGo在第37步的行動就是離散搜索，或者更近的例子是，DeepMind的Alpha Evol系統，都是離散搜索系統。因此，深度學習不會創造，但是搜索會。

### François Chollet <small>[25:00]</small>
那什麼是離散程序搜索？它基本上是針對某種語言或DSL中操作符的圖形的組合搜索。為了更好地理解，您可以試著在程序合成和您已經知道的機器學習技術之間畫出一個類比。在機器學習中，您的模型是一個可微分的參數函數，因此是一個曲線。在程序合成中，它將是一個離散圖形，一個運算符的圖形，來自某種語言。在機器學習中，您的學習引擎，即創建模型的方式是梯度下降，這在計算上非常高效。順便提一下，梯度下降將使您能夠非常快且高效地找到一個適合數據的模型。但在程序合成中，學習引擎是搜索，這是極其高效的。顯然，在機器學習中，您遇到的主要障礙是數據密度。為了擬合模型，您需要對數據流形進行密集取樣。您需要大量數據，而程序合成正好相反。程序合成非常具數據效率。您只需要兩到三個示例就能適合一個程序。為了找到該程序，您必須在潛在程序的巨大空間中篩選。該空間的大小隨著問題的複雜性增加而指數增長。所以，你們會遇到這個組合爆炸的瓶頸。我之前提到過，智能是兩種形式抽象的結合。第一類和第二類。如果只追求其中一種，你實際上無法走得太遠。不論是全心全意追求第1類還是全心全意追求第2類。我認為，若要真正釋放它們的潛力，您必須將它們結合在一起，這正是人類智能賦予我們的特殊之處。我们结合了感知和直觉，以及明确的逐步推理，将这两种形式的抽象结合在我们所有的思想和行为中。比如当你下棋时，你运用的是类型二抽象，当你一步一步展开一些潜在的动作时。但你不会对每一个可能的动作都做出这样的计算，因为它们实在是太多了。你只会对几个不同的选择展开计算，比如看看马和王后。因此，你通过直觉的方式进行选择，利用板上的模式识别缩小选择范围。你也正是通过体验潜移默化地提取这些模式，这正是类型一的抽象。所以，在类型一与类型二的推出如何结合呢？关键的系统二技术是离散搜索，超越组合爆炸，当中的阻碍是组合爆炸。而系统一的关键技术则是曲线拟合和对曲线的插值。因此，你收集大量数据，将它们嵌入到某种插值流形中，以便迅速、近似地做出对目标空间的判断，而大主意就是利用这些快速但近似的判断来抵抗组合爆炸，并让程序搜索变得可行。一个可以理解的简单类比是绘制地图。因此，你可以从一个离散物体的空间出发，拥有着离散关系，通常需要组合搜索而去做的事情，比如在地铁系统中找出路径，然后将这些物体嵌入某个潜在空间中，使用连续距离函数，可以快速做模糊的猜测，从而理解这些事物之间的潜在关系，而这能够使你在搜索时抵抗组合爆炸的影响。这就是当前我们正在开发的系统的全貌。AI将向相似程序员的系统发展，处理新任务就如同为其编写软件一样。当面对新任务时，程序员般的元学习者将即兴合成出一项适合该任务的程序或模型。这个程序将结合深度学习子模块与特定问题的类型二算法模块。这些模型将由一个离散的程序搜索系统組合而成，依托于对程序空间结构的深度学习驱动的直覺引導。这一搜索過程並不是從零開始，而是會使用現有的可重用抽象構建塊的全局庫，並且該庫會隨著不斷增長的任務而演化。因此，當出現新問題時，系統便會在這個庫中尋找相應的構建塊，任何在解決新問題的過程中合成出來的新構建塊，會被上傳回庫中。好比是，當你作為軟體工程師時，如果開發出一套對自己工作有用的庫，你會將其上傳至GitHub，以便其他人可以重用它。最終的目標是讓AI能面對一種全新的情境，利用其豐富的抽象庫，快速組合出一個有效的模型，正如人類軟體工程師利用現有工具和庫快速創造出軟體以解決新的問題一樣。而這個AI將通過拓展其抽象庫以及洗煉對程序空間結構的直覺，不斷改進。這個系統是我們在印度新研究實驗室正在構建的。我们启动印度的原因是，我们相信为了显著加速科学进步，我们需要能够独立发明和发现的AI。我们需要能够拓展知识边界的AI，而不仅仅是在其中操作。我们坚信，新的AI形式将是这种加速的关键。深度学习在自动化方面表现出色，极具价值，但科学发现需要更多。我们的Tendia方法是利用深度学习指导的程序搜索来建立这种编程者似的元学习者。为检验我们的进展，我们的第一个里程碑将是使用一套从未涉及ARKGI的系统来解决ARKGI。最终我们希望能利用这一系统推动科学，帮助人类研究员提速科学的时间线。

### François Chollet <small>[27:39]</small>
known AI systems today that are capable of some kind of uh uh invention, some kind of creativity, they rely on discrete search. Uh even back in the 90s, we were already using gigantic search to come up with new antenna designs. Or you can take uh Alph Go with move 37 that was discrete search or more recently the alpha evol system from deep mind all discrete search systems. So deep learning doesn't invent but search does. So what's discrete program search? It's basically combinatoral search over graphs of operators taken from some language, some DSL. And to better understand it, you can try to draw an analogy between program synthesis and the machine learning techniques you already know about. In machine learning, your model is a differentiable parametric function. So it's a curve. In program synthesis, it's going to be a discrete graph, a graph of ops, symbolic ops from some language. In ML, your learning engine, the way you create models is gradient descent, which is very comput efficient. By the way, gradient descent will let you find a model that fits the data very quickly, very efficiently. In program synthesis, the learning engine is searchal search, which is extremely compute efficient. Obviously in machine learning the key obstacle that you run into is data density. In order to fit a model you need a dense sampling of the data manifold. You need a lot of data and program synthesis is the exact reverse. Program synthes is extremely data efficient. You can fit a program using only two or three examples. But in order to find that program you have to sift through a vast space of potential programs. And the size of that space grows cuminally with problem complexity. So you run into this communatoral explosion wall. I said earlier that intelligence is a combination of two forms abstraction. Type one and type two. And I really don't think that you're going to go very far if you go all in on just one of them. Like all in on type one or all in on type two. I think that if you want to really unlock their potential, you have to combine them together. And that's what human intelligence is really good at. That's really what makes us special. We combine perception and intuition together with explicit step-by-step reasoning. We combine both forms of abstraction in all our thoughts, all our actions everywhere. For instance, when you're playing chess, you're using type two. when you calculate when you unfold some potential moves step by step in your mind. But you're not going to do this

### François Chollet <small>[30:17]</small>
mind. But you're not going to do this for every possible move, of course, because there are too many of them, right? You're only going to be doing it for a couple of different options, right? Like here, you're going to look at the knight, the queen. And the way you narrow down these options is via intuition, is via pattern recognition on the board. So, and you build that up very much through experience, right? You've mined your past experience unconsciously to extract these patterns and that's very much type one. So you're using type one intuition to make type two calculation tractable. So how is the merger between type one and type two going to work? Well the key system two technique is discrete search over a space of program one and the blocker that you run into is explosion. And meanwhile the key system one technique is uh curve fitting and interpolation on the curve. So you take a lot of data, you embed it on some kind of interpolating manifold that enables fast but approximate judgment calls about the target space and the big idea is going to be to leverage these fast but approximate judgment calls to fight commit explosion and make program search tractable. A simple analogy to understand this would be drawing a map. So you take a space of discrete objects with discrete relationships that would normally require connectal search like path finding on a subway system for instance and you embed these objects uh into a latent space where you can use a continuous distance function to make fast but approximate guesses about these great relationships and this enables you to keep explosion in check while doing search and this is what the full picture looks like. This is the system that we are currently working on. AI is going to move towards systems that are more like programmers that approach a new task by writing software for it. And when faced with a new task, your programmer like metalarner will synthesize on the fly a program or model that is adapted to the task. And this program will blend uh deep learning subm modules for type one sub problems like perception for instance and algorithmic modules uh for type two sub problems. And these models are going to be assembled by a discrete program search system that is guided by deep learning based intuition about the structure of program space. And this search process isn't done from scratch. is going to leverage a global library of reusable building blocks of abstractions. And that library is constantly evolving as it's learning

### François Chollet <small>[32:49]</small>
constantly evolving as it's learning from incoming tasks. So when a new problem appears, the system is going to search through this library for relevant building blocks. Uh and whenever in the in the course of solving a new problem, you're synthesizing a new building block. You're going to be uploading it back to the library. Much like as a software engineer, if you develop a useful library for your own work, you're going to put it on GitHub. so that other people can reuse it. And the ultimate goal here is to have an AI that can face a completely new situation and it's going to use its rich abstraction library uh to quickly assemble a working model much like a human software engineer can quickly create a piece of software to solve a new problem by leveraging existing tools in libraries. And this AI is going to keep improving itself over time both by expanding its library of abstractions and also by refining its intuition about the structure of program space. This system is what you are building at India our new research lab. We started India because we believe that in order to dramatically accelerate scientific progress we need AI that's capable of independent invention and discovery. We need AI that could expand the frontiers of knowledge, not just uh operate within them. And we really believe that a new form of AI is going to be key to this acceleration. Deep learning is great at automation. It's incredibly powerful for automation, but scientific discovery requires something more. And our approach at Tendia is to leverage a deep learning guided uh program search to build this uh programmer like metalarner. And to test our progress, our first milestone is going to be to solve RKGI using a system that starts at knowing nothing at all about RKGI. And you ultimately want to leverage our system for science to empower human researchers and help accelerate the timeline of science.
